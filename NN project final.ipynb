{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import gc\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching data from txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = ['combined_data_1.txt',\n",
    "         'combined_data_2.txt',\n",
    "         'combined_data_3.txt',\n",
    "         'combined_data_4.txt']\n",
    "movie = -1\n",
    "movies, users, ratings = [],[],[]\n",
    "\n",
    "for name in files:\n",
    "    with open(name, \"r\") as file:\n",
    "        for line in file:\n",
    "            if line.endswith(':\\n'):\n",
    "                movie = int(line.split(':')[0]) - 1\n",
    "            else:\n",
    "                user_rate = line.split(',')\n",
    "                user = int(user_rate[0])\n",
    "                rate = int(user_rate[1])\n",
    "                \n",
    "                movies.append(movie)\n",
    "                users.append(user)\n",
    "                ratings.append(rate)\n",
    "                \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to coordinate matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies = np.array(movies, dtype = np.int32)\n",
    "ratings = np.array(ratings, dtype = np.int8)\n",
    "users = np.array(users, dtype = np.int32)\n",
    "_, indices = np.unique(users, return_inverse=True)\n",
    "data = sp.coo_matrix((ratings, (indices, movies)), dtype = np.int8)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data to train-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_row, test_row, train_col, test_col, train_data, test_data = train_test_split(\n",
    "    data.row, data.col, data.data, test_size=0.2)\n",
    "\n",
    "shape = data.shape\n",
    "\n",
    "train = sp.coo_matrix(\n",
    "    (train_data, (train_row, train_col)), shape=shape, dtype = np.int8)\n",
    "test = sp.coo_matrix(\n",
    "    (test_data, (test_row, test_col)), shape=shape, dtype = np.int8)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DMF Model\n",
    "<img src=\"model.png\">\n",
    "\n",
    "### Input: User-Item non-zero ratings matrix Y\n",
    "### Output: User latent factor P , Item latent factor Q\n",
    "### Training algorithm: \n",
    "- Random wieghts initialization\n",
    "- for iter in range(max_iter)\n",
    " - for each interaction of User i and Item j in Y\n",
    "      1. Set \n",
    "      $\n",
    "      \\begin{align}\n",
    "                \\ P_i\n",
    "      \\end{align}\n",
    "      $\n",
    "        , \n",
    "      $\n",
    "      \\begin{align}\n",
    "                \\ Q_i\n",
    "      \\end{align}\n",
    "      $\n",
    "      using forward propagation \n",
    "      2. Set output: \n",
    "     $\n",
    "     \\begin{equation*}\n",
    "         \\hat{Y_{ij}} = cosine( \n",
    "         \\ P_i ,\n",
    "         \\ Q_j ) = \n",
    "         \\frac{P_i^T Q_j}{||P_i|| . ||Q_j||}\n",
    "     \\end{equation*}\n",
    "     $\n",
    "\n",
    "      3. Activation function: \n",
    "      $\n",
    "      \\begin{equation*}\n",
    "            \\hat{Y_{ij}} = max(µ, \n",
    "            \\hat{Y_{ij}} )\n",
    "      \\end{equation*}\n",
    "      $ \n",
    "                µ is a very small number i.e 10^-7\n",
    "      4. set Loss using this loss function:\n",
    "        \\begin{equation*}\n",
    "            Loss = \n",
    "            \\sum_{i, j->Y} \n",
    "            \\left( \n",
    "                \\frac{Y_{ij}}{max(Y)}\n",
    "                \\ log\n",
    "                \\hat{Y_{ij}}  +\n",
    "                \\left(1-\n",
    "                    \\frac{Y_{ij}}{max(Y)}\n",
    "                \\right)\n",
    "                \\ log( 1 - \n",
    "                \\hat{Y_{ij}} )\n",
    "            \\right) \n",
    "        \\end{equation*}\n",
    "                max(Y) is the max rating value (i.e 5)\n",
    "      5. Use back propagation to optimize model parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshape data with model input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "data_arr = data.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_arrT = data_arr.T\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 0 0 ... 3 0 4]\n",
      " [5 0 0 ... 0 0 0]\n",
      " [4 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(10000, 17770)\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 5 0 ... 0 0 0]\n",
      " [0 5 0 ... 0 0 0]\n",
      " [0 5 0 ... 0 0 0]]\n",
      "(10000, 480189)\n",
      "5\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "X1, X2, y = [],[],[]\n",
    "for idx in range(10000):\n",
    "    u, i, r = indices[idx], movies[idx], ratings[idx]\n",
    "    X1.append(data_arr[u])\n",
    "    X2.append(data_arrT[i])\n",
    "    y.append(r)\n",
    "\n",
    "X1 = np.array(X1)\n",
    "X2 = np.array(X2)\n",
    "y = np.array(y)\n",
    "\n",
    "X1_train, X1_test, X2_train, X2_test, y_train, y_test = train_test_split(\n",
    "    X1, X2, y, test_size=0.2)\n",
    "\n",
    "print(X1)\n",
    "print(X1.shape)\n",
    "\n",
    "print(X2)\n",
    "print(X2.shape)\n",
    "\n",
    "print(np.max(y))\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12822"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DMF:\n",
    "    \n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers      # layers has number of neurons in each layer\n",
    "    \n",
    "    @staticmethod\n",
    "    def cosine_similarity(inputs, epsilon=1.0e-6, delta=1e-12):\n",
    "        x, y = inputs[0], inputs[1]\n",
    "        numerator = keras.backend.sum(x * y, axis=1, keepdims=True)\n",
    "        denominator = keras.backend.sqrt(keras.backend.sum(x * x, axis=1, keepdims=True)\n",
    "                                       * keras.backend.sum(y * y, axis=1, keepdims=True))\n",
    "        cosine_similarity = numerator / keras.backend.maximum(denominator, delta)\n",
    "        return keras.backend.maximum(cosine_similarity, epsilon)\n",
    "    \n",
    "    @staticmethod\n",
    "    def loss_function(y_true, y_pred):\n",
    "        return -keras.backend.sum((\n",
    "              ( (y_true/5)       * keras.backend.log(y_pred) )\n",
    "            + ( (1 - (y_true/5)) * keras.backend.log(1 - y_pred) )\n",
    "        ))\n",
    "        \n",
    "    def build_model(self):\n",
    "        hidden_count = len(self.layers)\n",
    "        \n",
    "        P_input = keras.Input(shape=(17770,), name = 'P_input')\n",
    "        P_last = P_input\n",
    "        for i in range(hidden_count):\n",
    "            P_last = keras.layers.Dense(self.layers[i], activation=\"relu\", use_bias = True)(P_last)\n",
    "        \n",
    "        Q_input = keras.Input(shape=(480189,), name = 'Q_input')\n",
    "        Q_last = Q_input\n",
    "        for i in range(hidden_count):\n",
    "            Q_last = keras.layers.Dense(self.layers[i], activation=\"relu\", use_bias = True)(Q_last)\n",
    "        \n",
    "        output = keras.layers.Lambda(function=self.cosine_similarity, name='output')([P_last, Q_last])\n",
    "        \n",
    "        self.model = keras.Model(inputs=[P_input, Q_input], outputs=output, name=\"DMF_model\")\n",
    "        \n",
    "        self.model.summary()\n",
    "        \n",
    "        self.model.compile(\n",
    "            optimizer=keras.optimizers.Adam(lr=0.0001),\n",
    "            loss = self.loss_function,\n",
    "            metrics=[keras.metrics.RootMeanSquaredError(name = 'RMSE')]\n",
    "        )\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"DMF_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "P_input (InputLayer)            [(None, 17770)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Q_input (InputLayer)            [(None, 480189)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 84)           1492764     P_input[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 84)           40335960    Q_input[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 64)           5440        dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 64)           5440        dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "output (Lambda)                 (None, 1)            0           dense_17[0][0]                   \n",
      "                                                                 dense_19[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 41,839,604\n",
      "Trainable params: 41,839,604\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dmf = DMF(layers = [84, 64])\n",
    "dmf.build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "22/22 [==============================] - 18s 801ms/step - loss: 166.9537 - RMSE: 3.0234 - val_loss: 157.1381 - val_RMSE: 2.9899\n",
      "Epoch 2/600\n",
      "22/22 [==============================] - 14s 657ms/step - loss: 155.9299 - RMSE: 2.9693 - val_loss: 155.6819 - val_RMSE: 2.9758\n",
      "Epoch 3/600\n",
      "22/22 [==============================] - 15s 679ms/step - loss: 151.9522 - RMSE: 2.9639 - val_loss: 155.5995 - val_RMSE: 2.9641\n",
      "Epoch 4/600\n",
      "22/22 [==============================] - 15s 694ms/step - loss: 147.7768 - RMSE: 2.9533 - val_loss: 155.0117 - val_RMSE: 2.9764\n",
      "Epoch 5/600\n",
      "22/22 [==============================] - 15s 677ms/step - loss: 143.1206 - RMSE: 2.9483 - val_loss: 154.9042 - val_RMSE: 2.9810\n",
      "Epoch 6/600\n",
      "22/22 [==============================] - 14s 628ms/step - loss: 138.1533 - RMSE: 2.9388 - val_loss: 154.8006 - val_RMSE: 2.9780\n",
      "Epoch 7/600\n",
      "22/22 [==============================] - 12s 555ms/step - loss: 133.6458 - RMSE: 2.9291 - val_loss: 154.7913 - val_RMSE: 2.9720\n",
      "Epoch 8/600\n",
      "22/22 [==============================] - 15s 690ms/step - loss: 129.8774 - RMSE: 2.9206 - val_loss: 154.8029 - val_RMSE: 2.9802\n",
      "Epoch 9/600\n",
      "22/22 [==============================] - 15s 660ms/step - loss: 126.9977 - RMSE: 2.9130 - val_loss: 154.8487 - val_RMSE: 2.9768\n",
      "Epoch 10/600\n",
      "22/22 [==============================] - 16s 746ms/step - loss: 124.7399 - RMSE: 2.9063 - val_loss: 154.9312 - val_RMSE: 2.9785\n",
      "Epoch 11/600\n",
      "22/22 [==============================] - 14s 636ms/step - loss: 123.0774 - RMSE: 2.9019 - val_loss: 155.0271 - val_RMSE: 2.9722\n",
      "Epoch 12/600\n",
      "22/22 [==============================] - 15s 677ms/step - loss: 121.8069 - RMSE: 2.8972 - val_loss: 155.1783 - val_RMSE: 2.9764\n",
      "Epoch 13/600\n",
      "22/22 [==============================] - 16s 705ms/step - loss: 120.8450 - RMSE: 2.8945 - val_loss: 155.2162 - val_RMSE: 2.9777\n",
      "Epoch 14/600\n",
      "22/22 [==============================] - 16s 726ms/step - loss: 120.1068 - RMSE: 2.8923 - val_loss: 155.3513 - val_RMSE: 2.9702\n",
      "Epoch 15/600\n",
      "22/22 [==============================] - 16s 734ms/step - loss: 119.6140 - RMSE: 2.8902 - val_loss: 155.4683 - val_RMSE: 2.9733\n",
      "Epoch 16/600\n",
      "22/22 [==============================] - 16s 715ms/step - loss: 119.1651 - RMSE: 2.8888 - val_loss: 155.6073 - val_RMSE: 2.9740\n",
      "Epoch 17/600\n",
      "22/22 [==============================] - 15s 668ms/step - loss: 118.8250 - RMSE: 2.8876 - val_loss: 155.6664 - val_RMSE: 2.9724\n",
      "Epoch 18/600\n",
      "22/22 [==============================] - 15s 675ms/step - loss: 118.5727 - RMSE: 2.8865 - val_loss: 155.7987 - val_RMSE: 2.9727\n",
      "Epoch 19/600\n",
      "22/22 [==============================] - 15s 672ms/step - loss: 118.3046 - RMSE: 2.8857 - val_loss: 155.8336 - val_RMSE: 2.9701\n",
      "Epoch 20/600\n",
      "22/22 [==============================] - 16s 705ms/step - loss: 118.0967 - RMSE: 2.8848 - val_loss: 156.0132 - val_RMSE: 2.9696\n",
      "Epoch 21/600\n",
      "22/22 [==============================] - 14s 633ms/step - loss: 117.9432 - RMSE: 2.8843 - val_loss: 155.9576 - val_RMSE: 2.9676\n",
      "Epoch 22/600\n",
      "22/22 [==============================] - 15s 696ms/step - loss: 117.7917 - RMSE: 2.8835 - val_loss: 156.0320 - val_RMSE: 2.9679\n",
      "Epoch 23/600\n",
      "22/22 [==============================] - 16s 711ms/step - loss: 117.6414 - RMSE: 2.8832 - val_loss: 156.1348 - val_RMSE: 2.9675\n",
      "Epoch 24/600\n",
      "22/22 [==============================] - 17s 750ms/step - loss: 117.5553 - RMSE: 2.8826 - val_loss: 156.2239 - val_RMSE: 2.9676\n",
      "Epoch 25/600\n",
      "22/22 [==============================] - 16s 705ms/step - loss: 117.5120 - RMSE: 2.8822 - val_loss: 156.3695 - val_RMSE: 2.9703\n",
      "Epoch 26/600\n",
      "22/22 [==============================] - 14s 614ms/step - loss: 117.4010 - RMSE: 2.8818 - val_loss: 156.2836 - val_RMSE: 2.9679\n",
      "Epoch 27/600\n",
      "22/22 [==============================] - 16s 746ms/step - loss: 117.3829 - RMSE: 2.8818 - val_loss: 156.4521 - val_RMSE: 2.9633\n",
      "Epoch 28/600\n",
      "22/22 [==============================] - 16s 713ms/step - loss: 117.2833 - RMSE: 2.8813 - val_loss: 156.4578 - val_RMSE: 2.9677\n",
      "Epoch 29/600\n",
      "22/22 [==============================] - 17s 751ms/step - loss: 117.2187 - RMSE: 2.8810 - val_loss: 156.6163 - val_RMSE: 2.9641\n",
      "Epoch 30/600\n",
      "22/22 [==============================] - 14s 654ms/step - loss: 117.2005 - RMSE: 2.8808 - val_loss: 156.5947 - val_RMSE: 2.9644\n",
      "Epoch 31/600\n",
      "22/22 [==============================] - 17s 766ms/step - loss: 117.1628 - RMSE: 2.8808 - val_loss: 156.7628 - val_RMSE: 2.9619\n",
      "Epoch 32/600\n",
      "22/22 [==============================] - 16s 723ms/step - loss: 117.0906 - RMSE: 2.8806 - val_loss: 156.7218 - val_RMSE: 2.9641\n",
      "Epoch 33/600\n",
      "22/22 [==============================] - 16s 739ms/step - loss: 117.0313 - RMSE: 2.8802 - val_loss: 156.7760 - val_RMSE: 2.9625\n",
      "Epoch 34/600\n",
      "22/22 [==============================] - 16s 728ms/step - loss: 117.0357 - RMSE: 2.8803 - val_loss: 156.8297 - val_RMSE: 2.9576\n",
      "Epoch 35/600\n",
      "22/22 [==============================] - 15s 674ms/step - loss: 116.9862 - RMSE: 2.8797 - val_loss: 156.7645 - val_RMSE: 2.9633\n",
      "Epoch 36/600\n",
      "22/22 [==============================] - 15s 699ms/step - loss: 117.0005 - RMSE: 2.8800 - val_loss: 156.9069 - val_RMSE: 2.9603\n",
      "Epoch 37/600\n",
      "22/22 [==============================] - 15s 684ms/step - loss: 116.9866 - RMSE: 2.8798 - val_loss: 156.9232 - val_RMSE: 2.9597\n",
      "Epoch 38/600\n",
      "22/22 [==============================] - 15s 669ms/step - loss: 116.9049 - RMSE: 2.8795 - val_loss: 156.8820 - val_RMSE: 2.9591\n",
      "Epoch 39/600\n",
      "22/22 [==============================] - 15s 684ms/step - loss: 116.9301 - RMSE: 2.8796 - val_loss: 156.9093 - val_RMSE: 2.9579\n",
      "Epoch 40/600\n",
      "22/22 [==============================] - 14s 626ms/step - loss: 116.8853 - RMSE: 2.8791 - val_loss: 156.9245 - val_RMSE: 2.9625\n",
      "Epoch 41/600\n",
      "22/22 [==============================] - 15s 663ms/step - loss: 116.8618 - RMSE: 2.8794 - val_loss: 157.1208 - val_RMSE: 2.9541\n",
      "Epoch 42/600\n",
      "22/22 [==============================] - 14s 619ms/step - loss: 116.8553 - RMSE: 2.8792 - val_loss: 157.0236 - val_RMSE: 2.9560\n",
      "Epoch 43/600\n",
      "22/22 [==============================] - 14s 635ms/step - loss: 116.8600 - RMSE: 2.8792 - val_loss: 157.0305 - val_RMSE: 2.9582\n",
      "Epoch 44/600\n",
      "22/22 [==============================] - 13s 605ms/step - loss: 116.7952 - RMSE: 2.8789 - val_loss: 156.9443 - val_RMSE: 2.9578\n",
      "Epoch 45/600\n",
      "22/22 [==============================] - 13s 587ms/step - loss: 116.7433 - RMSE: 2.8790 - val_loss: 157.1589 - val_RMSE: 2.9543\n",
      "Epoch 46/600\n",
      "22/22 [==============================] - 15s 700ms/step - loss: 116.7236 - RMSE: 2.8789 - val_loss: 156.9778 - val_RMSE: 2.9550\n",
      "Epoch 47/600\n",
      "22/22 [==============================] - 15s 695ms/step - loss: 116.7390 - RMSE: 2.8788 - val_loss: 157.0530 - val_RMSE: 2.9556\n",
      "Epoch 48/600\n",
      "22/22 [==============================] - 15s 672ms/step - loss: 116.6859 - RMSE: 2.8788 - val_loss: 157.2186 - val_RMSE: 2.9515\n",
      "Epoch 49/600\n",
      "22/22 [==============================] - 15s 677ms/step - loss: 116.7042 - RMSE: 2.8789 - val_loss: 157.2604 - val_RMSE: 2.9540\n",
      "Epoch 50/600\n",
      "22/22 [==============================] - 15s 694ms/step - loss: 116.6915 - RMSE: 2.8784 - val_loss: 157.2616 - val_RMSE: 2.9536\n",
      "Epoch 51/600\n",
      "22/22 [==============================] - 15s 681ms/step - loss: 116.6512 - RMSE: 2.8788 - val_loss: 157.1618 - val_RMSE: 2.9517\n",
      "Epoch 52/600\n",
      "22/22 [==============================] - 15s 664ms/step - loss: 116.6794 - RMSE: 2.8785 - val_loss: 157.3025 - val_RMSE: 2.9515\n",
      "Epoch 53/600\n",
      "22/22 [==============================] - 15s 679ms/step - loss: 116.6748 - RMSE: 2.8788 - val_loss: 157.3474 - val_RMSE: 2.9478\n",
      "Epoch 54/600\n",
      "22/22 [==============================] - 15s 671ms/step - loss: 116.6670 - RMSE: 2.8784 - val_loss: 157.3935 - val_RMSE: 2.9511\n",
      "Epoch 55/600\n",
      "22/22 [==============================] - 14s 657ms/step - loss: 116.7138 - RMSE: 2.8784 - val_loss: 157.1656 - val_RMSE: 2.9534\n",
      "Epoch 56/600\n",
      "22/22 [==============================] - 14s 626ms/step - loss: 116.6421 - RMSE: 2.8783 - val_loss: 157.5302 - val_RMSE: 2.9486\n",
      "Epoch 57/600\n",
      "22/22 [==============================] - 15s 670ms/step - loss: 116.6961 - RMSE: 2.8786 - val_loss: 157.1548 - val_RMSE: 2.9537\n",
      "Epoch 58/600\n",
      "22/22 [==============================] - 14s 620ms/step - loss: 116.6493 - RMSE: 2.8782 - val_loss: 157.2081 - val_RMSE: 2.9547\n",
      "Epoch 59/600\n",
      "22/22 [==============================] - 14s 626ms/step - loss: 116.6669 - RMSE: 2.8786 - val_loss: 157.2157 - val_RMSE: 2.9534\n",
      "Epoch 60/600\n",
      "22/22 [==============================] - 14s 628ms/step - loss: 116.5989 - RMSE: 2.8781 - val_loss: 157.2634 - val_RMSE: 2.9587\n",
      "Epoch 61/600\n",
      "22/22 [==============================] - 15s 682ms/step - loss: 116.6274 - RMSE: 2.8783 - val_loss: 157.2831 - val_RMSE: 2.9504\n",
      "Epoch 62/600\n",
      "22/22 [==============================] - 16s 732ms/step - loss: 116.6347 - RMSE: 2.8785 - val_loss: 157.2828 - val_RMSE: 2.9515\n",
      "Epoch 63/600\n",
      "22/22 [==============================] - 15s 673ms/step - loss: 116.6247 - RMSE: 2.8784 - val_loss: 157.3215 - val_RMSE: 2.9504\n",
      "Epoch 64/600\n",
      "22/22 [==============================] - 13s 595ms/step - loss: 116.6256 - RMSE: 2.8781 - val_loss: 157.3235 - val_RMSE: 2.9510\n",
      "Epoch 65/600\n",
      "22/22 [==============================] - 15s 664ms/step - loss: 116.6001 - RMSE: 2.8782 - val_loss: 157.2411 - val_RMSE: 2.9489\n",
      "Epoch 66/600\n",
      "22/22 [==============================] - 14s 653ms/step - loss: 116.5818 - RMSE: 2.8783 - val_loss: 157.4718 - val_RMSE: 2.9434\n",
      "Epoch 67/600\n",
      "22/22 [==============================] - 15s 678ms/step - loss: 116.5925 - RMSE: 2.8781 - val_loss: 157.4264 - val_RMSE: 2.9489\n",
      "Epoch 68/600\n",
      "22/22 [==============================] - 14s 651ms/step - loss: 116.5453 - RMSE: 2.8783 - val_loss: 157.2278 - val_RMSE: 2.9499\n",
      "Epoch 69/600\n",
      "22/22 [==============================] - 15s 670ms/step - loss: 116.5833 - RMSE: 2.8779 - val_loss: 157.2667 - val_RMSE: 2.9546\n",
      "Epoch 70/600\n",
      "22/22 [==============================] - 15s 660ms/step - loss: 116.5915 - RMSE: 2.8782 - val_loss: 157.3669 - val_RMSE: 2.9458\n",
      "Epoch 71/600\n",
      "22/22 [==============================] - 14s 645ms/step - loss: 116.5488 - RMSE: 2.8781 - val_loss: 157.5363 - val_RMSE: 2.9419\n",
      "Epoch 72/600\n",
      "22/22 [==============================] - 15s 685ms/step - loss: 116.5855 - RMSE: 2.8780 - val_loss: 157.4460 - val_RMSE: 2.9470\n",
      "Epoch 73/600\n",
      "22/22 [==============================] - 15s 664ms/step - loss: 116.5458 - RMSE: 2.8780 - val_loss: 157.5442 - val_RMSE: 2.9432\n",
      "Epoch 74/600\n",
      "22/22 [==============================] - 14s 646ms/step - loss: 116.5269 - RMSE: 2.8784 - val_loss: 157.3824 - val_RMSE: 2.9440\n",
      "Epoch 75/600\n",
      "22/22 [==============================] - 13s 576ms/step - loss: 116.5601 - RMSE: 2.8775 - val_loss: 157.2091 - val_RMSE: 2.9505\n",
      "Epoch 76/600\n",
      "22/22 [==============================] - 14s 627ms/step - loss: 116.5434 - RMSE: 2.8783 - val_loss: 157.5094 - val_RMSE: 2.9429\n",
      "Epoch 77/600\n",
      "22/22 [==============================] - 15s 686ms/step - loss: 116.5334 - RMSE: 2.8780 - val_loss: 157.3677 - val_RMSE: 2.9458\n",
      "Epoch 78/600\n",
      "22/22 [==============================] - 14s 638ms/step - loss: 116.5271 - RMSE: 2.8781 - val_loss: 157.5979 - val_RMSE: 2.9400\n",
      "Epoch 79/600\n",
      "22/22 [==============================] - 15s 673ms/step - loss: 116.5147 - RMSE: 2.8777 - val_loss: 157.2117 - val_RMSE: 2.9487\n",
      "Epoch 80/600\n",
      "22/22 [==============================] - 15s 679ms/step - loss: 116.5078 - RMSE: 2.8781 - val_loss: 157.4847 - val_RMSE: 2.9417\n",
      "Epoch 81/600\n",
      "22/22 [==============================] - 15s 675ms/step - loss: 116.5105 - RMSE: 2.8780 - val_loss: 157.5011 - val_RMSE: 2.9445\n",
      "Epoch 82/600\n",
      "22/22 [==============================] - 14s 650ms/step - loss: 116.4538 - RMSE: 2.8777 - val_loss: 157.4263 - val_RMSE: 2.9456\n",
      "Epoch 83/600\n",
      "22/22 [==============================] - 15s 690ms/step - loss: 116.4956 - RMSE: 2.8780 - val_loss: 157.5939 - val_RMSE: 2.9414\n",
      "Epoch 84/600\n",
      "22/22 [==============================] - 14s 656ms/step - loss: 116.4855 - RMSE: 2.8780 - val_loss: 157.5876 - val_RMSE: 2.9411\n",
      "Epoch 85/600\n",
      "22/22 [==============================] - 14s 645ms/step - loss: 116.4716 - RMSE: 2.8778 - val_loss: 157.3339 - val_RMSE: 2.9464\n",
      "Epoch 86/600\n",
      "22/22 [==============================] - 14s 614ms/step - loss: 116.5003 - RMSE: 2.8780 - val_loss: 157.3861 - val_RMSE: 2.9429\n",
      "Epoch 87/600\n",
      "22/22 [==============================] - 15s 660ms/step - loss: 116.4950 - RMSE: 2.8777 - val_loss: 157.4621 - val_RMSE: 2.9417\n",
      "Epoch 88/600\n",
      "22/22 [==============================] - 13s 613ms/step - loss: 116.4628 - RMSE: 2.8780 - val_loss: 157.5566 - val_RMSE: 2.9412\n",
      "Epoch 89/600\n",
      "22/22 [==============================] - 12s 564ms/step - loss: 116.4256 - RMSE: 2.8777 - val_loss: 157.3602 - val_RMSE: 2.9463\n",
      "Epoch 90/600\n",
      "22/22 [==============================] - 14s 629ms/step - loss: 116.4432 - RMSE: 2.8778 - val_loss: 157.4146 - val_RMSE: 2.9444\n",
      "Epoch 91/600\n",
      "22/22 [==============================] - 15s 666ms/step - loss: 116.5082 - RMSE: 2.8778 - val_loss: 157.5521 - val_RMSE: 2.9416\n",
      "Epoch 92/600\n",
      "22/22 [==============================] - 13s 589ms/step - loss: 116.4484 - RMSE: 2.8777 - val_loss: 157.2456 - val_RMSE: 2.9470\n",
      "Epoch 93/600\n",
      "22/22 [==============================] - 14s 649ms/step - loss: 116.4712 - RMSE: 2.8779 - val_loss: 157.5215 - val_RMSE: 2.9409\n",
      "Epoch 94/600\n",
      "22/22 [==============================] - 16s 727ms/step - loss: 116.4913 - RMSE: 2.8778 - val_loss: 157.6744 - val_RMSE: 2.9403\n",
      "Epoch 95/600\n",
      "22/22 [==============================] - 16s 714ms/step - loss: 116.4395 - RMSE: 2.8778 - val_loss: 157.5998 - val_RMSE: 2.9398\n",
      "Epoch 96/600\n",
      "22/22 [==============================] - 13s 602ms/step - loss: 116.4764 - RMSE: 2.8778 - val_loss: 157.4151 - val_RMSE: 2.9408\n",
      "Epoch 97/600\n",
      "22/22 [==============================] - 15s 684ms/step - loss: 116.4912 - RMSE: 2.8776 - val_loss: 157.7489 - val_RMSE: 2.9355\n",
      "Epoch 98/600\n",
      "22/22 [==============================] - 15s 691ms/step - loss: 116.4873 - RMSE: 2.8779 - val_loss: 157.6974 - val_RMSE: 2.9348\n",
      "Epoch 99/600\n",
      "22/22 [==============================] - 13s 580ms/step - loss: 116.4475 - RMSE: 2.8777 - val_loss: 157.3581 - val_RMSE: 2.9418\n",
      "Epoch 100/600\n",
      "22/22 [==============================] - 13s 591ms/step - loss: 116.4692 - RMSE: 2.8777 - val_loss: 157.3823 - val_RMSE: 2.9410\n",
      "Epoch 101/600\n",
      "22/22 [==============================] - 16s 705ms/step - loss: 116.4371 - RMSE: 2.8777 - val_loss: 157.6274 - val_RMSE: 2.9378\n",
      "Epoch 102/600\n",
      "22/22 [==============================] - 14s 653ms/step - loss: 116.4908 - RMSE: 2.8779 - val_loss: 157.4409 - val_RMSE: 2.9402\n",
      "Epoch 103/600\n",
      "22/22 [==============================] - 15s 694ms/step - loss: 116.4534 - RMSE: 2.8777 - val_loss: 157.6174 - val_RMSE: 2.9354\n",
      "Epoch 104/600\n",
      "22/22 [==============================] - 15s 681ms/step - loss: 116.5022 - RMSE: 2.8781 - val_loss: 157.6112 - val_RMSE: 2.9359\n",
      "Epoch 105/600\n",
      "22/22 [==============================] - 15s 698ms/step - loss: 116.4961 - RMSE: 2.8774 - val_loss: 157.3507 - val_RMSE: 2.9413\n",
      "Epoch 106/600\n",
      "22/22 [==============================] - 15s 676ms/step - loss: 116.4407 - RMSE: 2.8779 - val_loss: 157.6583 - val_RMSE: 2.9341\n",
      "Epoch 107/600\n",
      "22/22 [==============================] - 15s 661ms/step - loss: 116.4539 - RMSE: 2.8778 - val_loss: 157.3332 - val_RMSE: 2.9412\n",
      "Epoch 108/600\n",
      "22/22 [==============================] - 14s 641ms/step - loss: 116.4708 - RMSE: 2.8777 - val_loss: 157.7276 - val_RMSE: 2.9343\n",
      "Epoch 109/600\n",
      "22/22 [==============================] - 13s 577ms/step - loss: 116.4512 - RMSE: 2.8777 - val_loss: 157.4330 - val_RMSE: 2.9380\n",
      "Epoch 110/600\n",
      "22/22 [==============================] - 14s 656ms/step - loss: 116.4474 - RMSE: 2.8778 - val_loss: 157.6430 - val_RMSE: 2.9339\n",
      "Epoch 111/600\n",
      "22/22 [==============================] - 14s 634ms/step - loss: 116.4398 - RMSE: 2.8775 - val_loss: 157.3910 - val_RMSE: 2.9369\n",
      "Epoch 112/600\n",
      "22/22 [==============================] - 14s 616ms/step - loss: 116.4419 - RMSE: 2.8777 - val_loss: 157.3408 - val_RMSE: 2.9369\n",
      "Epoch 113/600\n",
      "22/22 [==============================] - 13s 610ms/step - loss: 116.4248 - RMSE: 2.8778 - val_loss: 157.6882 - val_RMSE: 2.9329\n",
      "Epoch 114/600\n",
      "22/22 [==============================] - 16s 722ms/step - loss: 116.4512 - RMSE: 2.8779 - val_loss: 157.4830 - val_RMSE: 2.9361\n",
      "Epoch 115/600\n",
      "22/22 [==============================] - 16s 737ms/step - loss: 116.4832 - RMSE: 2.8774 - val_loss: 157.6044 - val_RMSE: 2.9369\n",
      "Epoch 116/600\n",
      "22/22 [==============================] - 14s 614ms/step - loss: 116.4485 - RMSE: 2.8780 - val_loss: 157.4828 - val_RMSE: 2.9339\n",
      "Epoch 117/600\n",
      "22/22 [==============================] - 11s 519ms/step - loss: 116.4232 - RMSE: 2.8776 - val_loss: 157.2710 - val_RMSE: 2.9373\n",
      "Epoch 118/600\n",
      "22/22 [==============================] - 13s 582ms/step - loss: 116.4495 - RMSE: 2.8777 - val_loss: 157.5535 - val_RMSE: 2.9334\n",
      "Epoch 119/600\n",
      "22/22 [==============================] - 12s 558ms/step - loss: 116.3898 - RMSE: 2.8776 - val_loss: 157.5256 - val_RMSE: 2.9341\n",
      "Epoch 120/600\n",
      "22/22 [==============================] - 11s 517ms/step - loss: 116.3664 - RMSE: 2.8778 - val_loss: 157.3122 - val_RMSE: 2.9373\n",
      "Epoch 121/600\n",
      "22/22 [==============================] - 11s 516ms/step - loss: 116.3986 - RMSE: 2.8777 - val_loss: 157.5444 - val_RMSE: 2.9316\n",
      "Epoch 122/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.4054 - RMSE: 2.8775 - val_loss: 157.4546 - val_RMSE: 2.9357\n",
      "Epoch 123/600\n",
      "22/22 [==============================] - 11s 512ms/step - loss: 116.4202 - RMSE: 2.8777 - val_loss: 157.5244 - val_RMSE: 2.9346\n",
      "Epoch 124/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.3968 - RMSE: 2.8777 - val_loss: 157.4907 - val_RMSE: 2.9321\n",
      "Epoch 125/600\n",
      "22/22 [==============================] - 11s 516ms/step - loss: 116.4260 - RMSE: 2.8776 - val_loss: 157.6472 - val_RMSE: 2.9341\n",
      "Epoch 126/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.4274 - RMSE: 2.8777 - val_loss: 157.3230 - val_RMSE: 2.9344\n",
      "Epoch 127/600\n",
      "22/22 [==============================] - 11s 515ms/step - loss: 116.4224 - RMSE: 2.8776 - val_loss: 157.6483 - val_RMSE: 2.9316\n",
      "Epoch 128/600\n",
      "22/22 [==============================] - 11s 517ms/step - loss: 116.4026 - RMSE: 2.8777 - val_loss: 157.4485 - val_RMSE: 2.9333\n",
      "Epoch 129/600\n",
      "22/22 [==============================] - 11s 516ms/step - loss: 116.4081 - RMSE: 2.8775 - val_loss: 157.4576 - val_RMSE: 2.9337\n",
      "Epoch 130/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.4300 - RMSE: 2.8778 - val_loss: 157.2910 - val_RMSE: 2.9356\n",
      "Epoch 131/600\n",
      "22/22 [==============================] - 11s 512ms/step - loss: 116.4319 - RMSE: 2.8776 - val_loss: 157.2888 - val_RMSE: 2.9353\n",
      "Epoch 132/600\n",
      "22/22 [==============================] - 11s 512ms/step - loss: 116.4248 - RMSE: 2.8778 - val_loss: 157.3915 - val_RMSE: 2.9354\n",
      "Epoch 133/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.3941 - RMSE: 2.8776 - val_loss: 157.7556 - val_RMSE: 2.9282\n",
      "Epoch 134/600\n",
      "22/22 [==============================] - 11s 511ms/step - loss: 116.4696 - RMSE: 2.8778 - val_loss: 157.3156 - val_RMSE: 2.9332\n",
      "Epoch 135/600\n",
      "22/22 [==============================] - 11s 519ms/step - loss: 116.4135 - RMSE: 2.8775 - val_loss: 157.2051 - val_RMSE: 2.9368\n",
      "Epoch 136/600\n",
      "22/22 [==============================] - 11s 520ms/step - loss: 116.4273 - RMSE: 2.8776 - val_loss: 157.3693 - val_RMSE: 2.9323\n",
      "Epoch 137/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.3678 - RMSE: 2.8777 - val_loss: 157.3156 - val_RMSE: 2.9320\n",
      "Epoch 138/600\n",
      "22/22 [==============================] - 11s 515ms/step - loss: 116.4205 - RMSE: 2.8776 - val_loss: 157.7688 - val_RMSE: 2.9275\n",
      "Epoch 139/600\n",
      "22/22 [==============================] - 11s 516ms/step - loss: 116.4026 - RMSE: 2.8776 - val_loss: 157.1404 - val_RMSE: 2.9341\n",
      "Epoch 140/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.3821 - RMSE: 2.8776 - val_loss: 157.3620 - val_RMSE: 2.9328\n",
      "Epoch 141/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.3969 - RMSE: 2.8776 - val_loss: 157.4741 - val_RMSE: 2.9283\n",
      "Epoch 142/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.4319 - RMSE: 2.8778 - val_loss: 157.8650 - val_RMSE: 2.9246\n",
      "Epoch 143/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.4137 - RMSE: 2.8774 - val_loss: 157.4211 - val_RMSE: 2.9308\n",
      "Epoch 144/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.3750 - RMSE: 2.8778 - val_loss: 157.4875 - val_RMSE: 2.9284\n",
      "Epoch 145/600\n",
      "22/22 [==============================] - 11s 518ms/step - loss: 116.4206 - RMSE: 2.8775 - val_loss: 157.1811 - val_RMSE: 2.9318\n",
      "Epoch 146/600\n",
      "22/22 [==============================] - 11s 515ms/step - loss: 116.4131 - RMSE: 2.8775 - val_loss: 157.2324 - val_RMSE: 2.9326\n",
      "Epoch 147/600\n",
      "22/22 [==============================] - 11s 513ms/step - loss: 116.3752 - RMSE: 2.8776 - val_loss: 157.3660 - val_RMSE: 2.9285\n",
      "Epoch 148/600\n",
      "22/22 [==============================] - 11s 513ms/step - loss: 116.4034 - RMSE: 2.8778 - val_loss: 157.8885 - val_RMSE: 2.9232\n",
      "Epoch 149/600\n",
      "22/22 [==============================] - 11s 512ms/step - loss: 116.4252 - RMSE: 2.8773 - val_loss: 156.8605 - val_RMSE: 2.9362\n",
      "Epoch 150/600\n",
      "22/22 [==============================] - 11s 513ms/step - loss: 116.4043 - RMSE: 2.8778 - val_loss: 157.6593 - val_RMSE: 2.9255\n",
      "Epoch 151/600\n",
      "22/22 [==============================] - 11s 515ms/step - loss: 116.3677 - RMSE: 2.8777 - val_loss: 157.3584 - val_RMSE: 2.9267\n",
      "Epoch 152/600\n",
      "22/22 [==============================] - 11s 511ms/step - loss: 116.4156 - RMSE: 2.8774 - val_loss: 157.1178 - val_RMSE: 2.9326\n",
      "Epoch 153/600\n",
      "22/22 [==============================] - 11s 515ms/step - loss: 116.3849 - RMSE: 2.8776 - val_loss: 157.1873 - val_RMSE: 2.9288\n",
      "Epoch 154/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.4100 - RMSE: 2.8776 - val_loss: 157.3462 - val_RMSE: 2.9277\n",
      "Epoch 155/600\n",
      "22/22 [==============================] - 11s 512ms/step - loss: 116.4011 - RMSE: 2.8778 - val_loss: 157.4595 - val_RMSE: 2.9268\n",
      "Epoch 156/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.4025 - RMSE: 2.8775 - val_loss: 157.3362 - val_RMSE: 2.9270\n",
      "Epoch 157/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.4099 - RMSE: 2.8776 - val_loss: 157.5161 - val_RMSE: 2.9250\n",
      "Epoch 158/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.3633 - RMSE: 2.8776 - val_loss: 157.3202 - val_RMSE: 2.9289\n",
      "Epoch 159/600\n",
      "22/22 [==============================] - 11s 516ms/step - loss: 116.3664 - RMSE: 2.8775 - val_loss: 157.1451 - val_RMSE: 2.9304\n",
      "Epoch 160/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.4285 - RMSE: 2.8777 - val_loss: 157.4751 - val_RMSE: 2.9248\n",
      "Epoch 161/600\n",
      "22/22 [==============================] - 11s 520ms/step - loss: 116.3818 - RMSE: 2.8775 - val_loss: 157.1009 - val_RMSE: 2.9287\n",
      "Epoch 162/600\n",
      "22/22 [==============================] - 11s 517ms/step - loss: 116.3859 - RMSE: 2.8777 - val_loss: 157.4989 - val_RMSE: 2.9257\n",
      "Epoch 163/600\n",
      "22/22 [==============================] - 11s 515ms/step - loss: 116.3591 - RMSE: 2.8775 - val_loss: 157.0356 - val_RMSE: 2.9289\n",
      "Epoch 164/600\n",
      "22/22 [==============================] - 11s 513ms/step - loss: 116.3328 - RMSE: 2.8775 - val_loss: 157.3851 - val_RMSE: 2.9256\n",
      "Epoch 165/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.3336 - RMSE: 2.8777 - val_loss: 157.4151 - val_RMSE: 2.9246\n",
      "Epoch 166/600\n",
      "22/22 [==============================] - 11s 513ms/step - loss: 116.3728 - RMSE: 2.8774 - val_loss: 157.3011 - val_RMSE: 2.9273\n",
      "Epoch 167/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.3651 - RMSE: 2.8776 - val_loss: 157.0179 - val_RMSE: 2.9287\n",
      "Epoch 168/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.3463 - RMSE: 2.8775 - val_loss: 157.4167 - val_RMSE: 2.9257\n",
      "Epoch 169/600\n",
      "22/22 [==============================] - 11s 513ms/step - loss: 116.3510 - RMSE: 2.8775 - val_loss: 157.3101 - val_RMSE: 2.9251\n",
      "Epoch 170/600\n",
      "22/22 [==============================] - 11s 515ms/step - loss: 116.3501 - RMSE: 2.8775 - val_loss: 157.0873 - val_RMSE: 2.9290\n",
      "Epoch 171/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.3448 - RMSE: 2.8775 - val_loss: 157.1550 - val_RMSE: 2.9273\n",
      "Epoch 172/600\n",
      "22/22 [==============================] - 11s 513ms/step - loss: 116.3317 - RMSE: 2.8777 - val_loss: 157.5478 - val_RMSE: 2.9235\n",
      "Epoch 173/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.3359 - RMSE: 2.8774 - val_loss: 157.2685 - val_RMSE: 2.9245\n",
      "Epoch 174/600\n",
      "22/22 [==============================] - 11s 512ms/step - loss: 116.3588 - RMSE: 2.8777 - val_loss: 157.3638 - val_RMSE: 2.9239\n",
      "Epoch 175/600\n",
      "22/22 [==============================] - 11s 512ms/step - loss: 116.4097 - RMSE: 2.8774 - val_loss: 157.4720 - val_RMSE: 2.9225\n",
      "Epoch 176/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.3857 - RMSE: 2.8777 - val_loss: 157.3391 - val_RMSE: 2.9259\n",
      "Epoch 177/600\n",
      "22/22 [==============================] - 11s 512ms/step - loss: 116.3710 - RMSE: 2.8773 - val_loss: 157.2339 - val_RMSE: 2.9241\n",
      "Epoch 178/600\n",
      "22/22 [==============================] - 11s 511ms/step - loss: 116.3250 - RMSE: 2.8776 - val_loss: 157.2318 - val_RMSE: 2.9250\n",
      "Epoch 179/600\n",
      "22/22 [==============================] - 11s 515ms/step - loss: 116.3596 - RMSE: 2.8775 - val_loss: 157.2482 - val_RMSE: 2.9254\n",
      "Epoch 180/600\n",
      "22/22 [==============================] - 11s 516ms/step - loss: 116.4059 - RMSE: 2.8776 - val_loss: 157.2546 - val_RMSE: 2.9231\n",
      "Epoch 181/600\n",
      "22/22 [==============================] - 11s 513ms/step - loss: 116.4329 - RMSE: 2.8776 - val_loss: 157.1683 - val_RMSE: 2.9240\n",
      "Epoch 182/600\n",
      "22/22 [==============================] - 11s 513ms/step - loss: 116.4041 - RMSE: 2.8775 - val_loss: 157.4086 - val_RMSE: 2.9210\n",
      "Epoch 183/600\n",
      "22/22 [==============================] - 11s 516ms/step - loss: 116.3563 - RMSE: 2.8774 - val_loss: 157.2838 - val_RMSE: 2.9229\n",
      "Epoch 184/600\n",
      "22/22 [==============================] - 11s 512ms/step - loss: 116.3453 - RMSE: 2.8776 - val_loss: 157.3537 - val_RMSE: 2.9217\n",
      "Epoch 185/600\n",
      "22/22 [==============================] - 11s 517ms/step - loss: 116.3662 - RMSE: 2.8775 - val_loss: 157.2328 - val_RMSE: 2.9235\n",
      "Epoch 186/600\n",
      "22/22 [==============================] - 11s 515ms/step - loss: 116.3961 - RMSE: 2.8776 - val_loss: 157.2475 - val_RMSE: 2.9222\n",
      "Epoch 187/600\n",
      "22/22 [==============================] - 11s 516ms/step - loss: 116.3359 - RMSE: 2.8776 - val_loss: 157.2711 - val_RMSE: 2.9196\n",
      "Epoch 188/600\n",
      "22/22 [==============================] - 11s 513ms/step - loss: 116.3895 - RMSE: 2.8776 - val_loss: 157.2001 - val_RMSE: 2.9229\n",
      "Epoch 189/600\n",
      "22/22 [==============================] - 11s 513ms/step - loss: 116.3902 - RMSE: 2.8775 - val_loss: 157.0040 - val_RMSE: 2.9228\n",
      "Epoch 190/600\n",
      "22/22 [==============================] - 11s 513ms/step - loss: 116.3433 - RMSE: 2.8775 - val_loss: 157.1390 - val_RMSE: 2.9227\n",
      "Epoch 191/600\n",
      "22/22 [==============================] - 11s 518ms/step - loss: 116.3675 - RMSE: 2.8775 - val_loss: 156.5369 - val_RMSE: 2.9283\n",
      "Epoch 192/600\n",
      "22/22 [==============================] - 12s 525ms/step - loss: 116.3997 - RMSE: 2.8776 - val_loss: 156.7054 - val_RMSE: 2.9303\n",
      "Epoch 193/600\n",
      "22/22 [==============================] - 12s 524ms/step - loss: 116.3878 - RMSE: 2.8776 - val_loss: 157.1569 - val_RMSE: 2.9209\n",
      "Epoch 194/600\n",
      "22/22 [==============================] - 11s 512ms/step - loss: 116.4076 - RMSE: 2.8777 - val_loss: 157.0588 - val_RMSE: 2.9245\n",
      "Epoch 195/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.3877 - RMSE: 2.8774 - val_loss: 157.1026 - val_RMSE: 2.9202\n",
      "Epoch 196/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.3979 - RMSE: 2.8776 - val_loss: 157.4965 - val_RMSE: 2.9191\n",
      "Epoch 197/600\n",
      "22/22 [==============================] - 11s 512ms/step - loss: 116.3699 - RMSE: 2.8776 - val_loss: 156.8495 - val_RMSE: 2.9222\n",
      "Epoch 198/600\n",
      "22/22 [==============================] - 11s 512ms/step - loss: 116.3531 - RMSE: 2.8775 - val_loss: 157.1550 - val_RMSE: 2.9201\n",
      "Epoch 199/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.3875 - RMSE: 2.8775 - val_loss: 157.1815 - val_RMSE: 2.9200\n",
      "Epoch 200/600\n",
      "22/22 [==============================] - 11s 513ms/step - loss: 116.3729 - RMSE: 2.8776 - val_loss: 156.9565 - val_RMSE: 2.9238\n",
      "Epoch 201/600\n",
      "22/22 [==============================] - 11s 512ms/step - loss: 116.3604 - RMSE: 2.8772 - val_loss: 156.7089 - val_RMSE: 2.9256\n",
      "Epoch 202/600\n",
      "22/22 [==============================] - 11s 512ms/step - loss: 116.3873 - RMSE: 2.8777 - val_loss: 157.0167 - val_RMSE: 2.9211\n",
      "Epoch 203/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.3468 - RMSE: 2.8775 - val_loss: 156.8490 - val_RMSE: 2.9218\n",
      "Epoch 204/600\n",
      "22/22 [==============================] - 11s 512ms/step - loss: 116.3516 - RMSE: 2.8775 - val_loss: 156.9129 - val_RMSE: 2.9227\n",
      "Epoch 205/600\n",
      "22/22 [==============================] - 11s 515ms/step - loss: 116.3167 - RMSE: 2.8775 - val_loss: 156.9575 - val_RMSE: 2.9215\n",
      "Epoch 206/600\n",
      "22/22 [==============================] - 11s 512ms/step - loss: 116.3718 - RMSE: 2.8775 - val_loss: 156.8339 - val_RMSE: 2.9242\n",
      "Epoch 207/600\n",
      "22/22 [==============================] - 11s 517ms/step - loss: 116.3551 - RMSE: 2.8773 - val_loss: 156.8178 - val_RMSE: 2.9226\n",
      "Epoch 208/600\n",
      "22/22 [==============================] - 11s 512ms/step - loss: 116.3586 - RMSE: 2.8777 - val_loss: 157.1279 - val_RMSE: 2.9179\n",
      "Epoch 209/600\n",
      "22/22 [==============================] - 11s 522ms/step - loss: 116.3673 - RMSE: 2.8775 - val_loss: 157.3217 - val_RMSE: 2.9164\n",
      "Epoch 210/600\n",
      "22/22 [==============================] - 12s 536ms/step - loss: 116.3555 - RMSE: 2.8774 - val_loss: 156.7943 - val_RMSE: 2.9247\n",
      "Epoch 211/600\n",
      "22/22 [==============================] - 11s 516ms/step - loss: 116.3349 - RMSE: 2.8775 - val_loss: 156.9333 - val_RMSE: 2.9196\n",
      "Epoch 212/600\n",
      "22/22 [==============================] - 11s 518ms/step - loss: 116.3265 - RMSE: 2.8776 - val_loss: 157.0435 - val_RMSE: 2.9183\n",
      "Epoch 213/600\n",
      "22/22 [==============================] - 11s 520ms/step - loss: 116.3160 - RMSE: 2.8773 - val_loss: 156.6922 - val_RMSE: 2.9243\n",
      "Epoch 214/600\n",
      "22/22 [==============================] - 11s 515ms/step - loss: 116.3279 - RMSE: 2.8776 - val_loss: 157.1792 - val_RMSE: 2.9174\n",
      "Epoch 215/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.3403 - RMSE: 2.8774 - val_loss: 156.9065 - val_RMSE: 2.9190\n",
      "Epoch 216/600\n",
      "22/22 [==============================] - 11s 513ms/step - loss: 116.3385 - RMSE: 2.8777 - val_loss: 156.9612 - val_RMSE: 2.9201\n",
      "Epoch 217/600\n",
      "22/22 [==============================] - 11s 519ms/step - loss: 116.3575 - RMSE: 2.8773 - val_loss: 157.1101 - val_RMSE: 2.9179\n",
      "Epoch 218/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.3643 - RMSE: 2.8775 - val_loss: 157.1296 - val_RMSE: 2.9181\n",
      "Epoch 219/600\n",
      "22/22 [==============================] - 11s 515ms/step - loss: 116.3818 - RMSE: 2.8774 - val_loss: 157.0019 - val_RMSE: 2.9203\n",
      "Epoch 220/600\n",
      "22/22 [==============================] - 11s 515ms/step - loss: 116.3111 - RMSE: 2.8775 - val_loss: 156.9519 - val_RMSE: 2.9188\n",
      "Epoch 221/600\n",
      "22/22 [==============================] - 11s 516ms/step - loss: 116.3058 - RMSE: 2.8774 - val_loss: 156.9787 - val_RMSE: 2.9175\n",
      "Epoch 222/600\n",
      "22/22 [==============================] - 11s 515ms/step - loss: 116.3631 - RMSE: 2.8777 - val_loss: 156.7680 - val_RMSE: 2.9192\n",
      "Epoch 223/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.3423 - RMSE: 2.8774 - val_loss: 157.1055 - val_RMSE: 2.9166\n",
      "Epoch 224/600\n",
      "22/22 [==============================] - 11s 518ms/step - loss: 116.3181 - RMSE: 2.8776 - val_loss: 156.9235 - val_RMSE: 2.9180\n",
      "Epoch 225/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.3556 - RMSE: 2.8773 - val_loss: 156.7555 - val_RMSE: 2.9214\n",
      "Epoch 226/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.3272 - RMSE: 2.8775 - val_loss: 156.6386 - val_RMSE: 2.9184\n",
      "Epoch 227/600\n",
      "22/22 [==============================] - 11s 517ms/step - loss: 116.3225 - RMSE: 2.8775 - val_loss: 156.9740 - val_RMSE: 2.9184\n",
      "Epoch 228/600\n",
      "22/22 [==============================] - 11s 515ms/step - loss: 116.3353 - RMSE: 2.8775 - val_loss: 156.7172 - val_RMSE: 2.9196\n",
      "Epoch 229/600\n",
      "22/22 [==============================] - 11s 515ms/step - loss: 116.3432 - RMSE: 2.8773 - val_loss: 156.6740 - val_RMSE: 2.9196\n",
      "Epoch 230/600\n",
      "22/22 [==============================] - 11s 518ms/step - loss: 116.3222 - RMSE: 2.8777 - val_loss: 157.0401 - val_RMSE: 2.9163\n",
      "Epoch 231/600\n",
      "22/22 [==============================] - 11s 517ms/step - loss: 116.3424 - RMSE: 2.8774 - val_loss: 156.6158 - val_RMSE: 2.9213\n",
      "Epoch 232/600\n",
      "22/22 [==============================] - 11s 518ms/step - loss: 116.3456 - RMSE: 2.8774 - val_loss: 156.8486 - val_RMSE: 2.9189\n",
      "Epoch 233/600\n",
      "22/22 [==============================] - 11s 517ms/step - loss: 116.3052 - RMSE: 2.8773 - val_loss: 156.6114 - val_RMSE: 2.9208\n",
      "Epoch 234/600\n",
      "22/22 [==============================] - 11s 519ms/step - loss: 116.3290 - RMSE: 2.8777 - val_loss: 156.8952 - val_RMSE: 2.9168\n",
      "Epoch 235/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.3450 - RMSE: 2.8774 - val_loss: 156.9494 - val_RMSE: 2.9164\n",
      "Epoch 236/600\n",
      "22/22 [==============================] - 11s 516ms/step - loss: 116.3207 - RMSE: 2.8775 - val_loss: 157.0325 - val_RMSE: 2.9152\n",
      "Epoch 237/600\n",
      "22/22 [==============================] - 11s 520ms/step - loss: 116.3710 - RMSE: 2.8774 - val_loss: 156.5872 - val_RMSE: 2.9194\n",
      "Epoch 238/600\n",
      "22/22 [==============================] - 11s 519ms/step - loss: 116.3511 - RMSE: 2.8775 - val_loss: 156.5400 - val_RMSE: 2.9201\n",
      "Epoch 239/600\n",
      "22/22 [==============================] - 11s 516ms/step - loss: 116.3342 - RMSE: 2.8773 - val_loss: 156.8590 - val_RMSE: 2.9167\n",
      "Epoch 240/600\n",
      "22/22 [==============================] - 11s 516ms/step - loss: 116.4038 - RMSE: 2.8776 - val_loss: 156.8307 - val_RMSE: 2.9145\n",
      "Epoch 241/600\n",
      "22/22 [==============================] - 11s 517ms/step - loss: 116.3706 - RMSE: 2.8776 - val_loss: 156.9541 - val_RMSE: 2.9136\n",
      "Epoch 242/600\n",
      "22/22 [==============================] - 11s 517ms/step - loss: 116.3731 - RMSE: 2.8776 - val_loss: 157.0358 - val_RMSE: 2.9138\n",
      "Epoch 243/600\n",
      "22/22 [==============================] - 11s 516ms/step - loss: 116.3404 - RMSE: 2.8773 - val_loss: 156.3869 - val_RMSE: 2.9206\n",
      "Epoch 244/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.3274 - RMSE: 2.8775 - val_loss: 156.8421 - val_RMSE: 2.9172\n",
      "Epoch 245/600\n",
      "22/22 [==============================] - 11s 515ms/step - loss: 116.3800 - RMSE: 2.8775 - val_loss: 157.1680 - val_RMSE: 2.9122\n",
      "Epoch 246/600\n",
      "22/22 [==============================] - 11s 515ms/step - loss: 116.3288 - RMSE: 2.8776 - val_loss: 156.5998 - val_RMSE: 2.9172\n",
      "Epoch 247/600\n",
      "22/22 [==============================] - 11s 517ms/step - loss: 116.3632 - RMSE: 2.8772 - val_loss: 156.7465 - val_RMSE: 2.9179\n",
      "Epoch 248/600\n",
      "22/22 [==============================] - 11s 513ms/step - loss: 116.3465 - RMSE: 2.8777 - val_loss: 156.9448 - val_RMSE: 2.9137\n",
      "Epoch 249/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.3501 - RMSE: 2.8775 - val_loss: 157.0202 - val_RMSE: 2.9130\n",
      "Epoch 250/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.3288 - RMSE: 2.8774 - val_loss: 156.9922 - val_RMSE: 2.9119\n",
      "Epoch 251/600\n",
      "22/22 [==============================] - 11s 516ms/step - loss: 116.3609 - RMSE: 2.8775 - val_loss: 156.8626 - val_RMSE: 2.9143\n",
      "Epoch 252/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.3631 - RMSE: 2.8776 - val_loss: 156.9729 - val_RMSE: 2.9122\n",
      "Epoch 253/600\n",
      "22/22 [==============================] - 11s 515ms/step - loss: 116.3491 - RMSE: 2.8773 - val_loss: 156.7937 - val_RMSE: 2.9147\n",
      "Epoch 254/600\n",
      "22/22 [==============================] - 11s 517ms/step - loss: 116.3391 - RMSE: 2.8775 - val_loss: 156.4495 - val_RMSE: 2.9173\n",
      "Epoch 255/600\n",
      "22/22 [==============================] - 11s 515ms/step - loss: 116.3090 - RMSE: 2.8773 - val_loss: 156.2854 - val_RMSE: 2.9205\n",
      "Epoch 256/600\n",
      "22/22 [==============================] - 11s 515ms/step - loss: 116.3427 - RMSE: 2.8777 - val_loss: 156.8356 - val_RMSE: 2.9113\n",
      "Epoch 257/600\n",
      "22/22 [==============================] - 11s 515ms/step - loss: 116.3206 - RMSE: 2.8773 - val_loss: 156.4949 - val_RMSE: 2.9180\n",
      "Epoch 258/600\n",
      "22/22 [==============================] - 11s 517ms/step - loss: 116.3385 - RMSE: 2.8774 - val_loss: 156.6124 - val_RMSE: 2.9173\n",
      "Epoch 259/600\n",
      "22/22 [==============================] - 11s 516ms/step - loss: 116.3687 - RMSE: 2.8775 - val_loss: 156.9326 - val_RMSE: 2.9102\n",
      "Epoch 260/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.3163 - RMSE: 2.8775 - val_loss: 156.6391 - val_RMSE: 2.9149\n",
      "Epoch 261/600\n",
      "22/22 [==============================] - 11s 515ms/step - loss: 116.3234 - RMSE: 2.8773 - val_loss: 156.3895 - val_RMSE: 2.9176\n",
      "Epoch 262/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.3099 - RMSE: 2.8776 - val_loss: 156.7892 - val_RMSE: 2.9135\n",
      "Epoch 263/600\n",
      "22/22 [==============================] - 11s 519ms/step - loss: 116.3302 - RMSE: 2.8773 - val_loss: 156.7841 - val_RMSE: 2.9135\n",
      "Epoch 264/600\n",
      "22/22 [==============================] - 11s 519ms/step - loss: 116.3202 - RMSE: 2.8774 - val_loss: 156.4923 - val_RMSE: 2.9152\n",
      "Epoch 265/600\n",
      "22/22 [==============================] - 11s 516ms/step - loss: 116.3025 - RMSE: 2.8773 - val_loss: 156.5032 - val_RMSE: 2.9166\n",
      "Epoch 266/600\n",
      "22/22 [==============================] - 11s 516ms/step - loss: 116.3272 - RMSE: 2.8776 - val_loss: 156.5844 - val_RMSE: 2.9147\n",
      "Epoch 267/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.2894 - RMSE: 2.8773 - val_loss: 156.4158 - val_RMSE: 2.9163\n",
      "Epoch 268/600\n",
      "22/22 [==============================] - 12s 524ms/step - loss: 116.2912 - RMSE: 2.8776 - val_loss: 156.6619 - val_RMSE: 2.9131\n",
      "Epoch 269/600\n",
      "22/22 [==============================] - 11s 515ms/step - loss: 116.2925 - RMSE: 2.8774 - val_loss: 156.6365 - val_RMSE: 2.9153\n",
      "Epoch 270/600\n",
      "22/22 [==============================] - 11s 517ms/step - loss: 116.2807 - RMSE: 2.8774 - val_loss: 156.5744 - val_RMSE: 2.9139\n",
      "Epoch 271/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.2870 - RMSE: 2.8774 - val_loss: 156.6809 - val_RMSE: 2.9133\n",
      "Epoch 272/600\n",
      "22/22 [==============================] - 11s 521ms/step - loss: 116.3051 - RMSE: 2.8774 - val_loss: 156.6216 - val_RMSE: 2.9128\n",
      "Epoch 273/600\n",
      "22/22 [==============================] - 12s 532ms/step - loss: 116.3067 - RMSE: 2.8775 - val_loss: 156.9845 - val_RMSE: 2.9109\n",
      "Epoch 274/600\n",
      "22/22 [==============================] - 11s 516ms/step - loss: 116.3042 - RMSE: 2.8774 - val_loss: 156.6125 - val_RMSE: 2.9126\n",
      "Epoch 275/600\n",
      "22/22 [==============================] - 11s 517ms/step - loss: 116.3101 - RMSE: 2.8775 - val_loss: 156.7921 - val_RMSE: 2.9126\n",
      "Epoch 276/600\n",
      "22/22 [==============================] - 11s 516ms/step - loss: 116.2966 - RMSE: 2.8773 - val_loss: 156.5698 - val_RMSE: 2.9137\n",
      "Epoch 277/600\n",
      "22/22 [==============================] - 11s 515ms/step - loss: 116.3532 - RMSE: 2.8775 - val_loss: 156.2543 - val_RMSE: 2.9177\n",
      "Epoch 278/600\n",
      "22/22 [==============================] - 11s 519ms/step - loss: 116.2916 - RMSE: 2.8775 - val_loss: 156.0647 - val_RMSE: 2.9188\n",
      "Epoch 279/600\n",
      "22/22 [==============================] - 12s 523ms/step - loss: 116.3152 - RMSE: 2.8774 - val_loss: 156.5291 - val_RMSE: 2.9146\n",
      "Epoch 280/600\n",
      "22/22 [==============================] - 12s 539ms/step - loss: 116.2933 - RMSE: 2.8775 - val_loss: 156.4729 - val_RMSE: 2.9134\n",
      "Epoch 281/600\n",
      "22/22 [==============================] - 11s 519ms/step - loss: 116.3467 - RMSE: 2.8773 - val_loss: 156.3357 - val_RMSE: 2.9162\n",
      "Epoch 282/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.3333 - RMSE: 2.8774 - val_loss: 156.2710 - val_RMSE: 2.9146\n",
      "Epoch 283/600\n",
      "22/22 [==============================] - 11s 515ms/step - loss: 116.3171 - RMSE: 2.8776 - val_loss: 156.5313 - val_RMSE: 2.9131\n",
      "Epoch 284/600\n",
      "22/22 [==============================] - 11s 513ms/step - loss: 116.3753 - RMSE: 2.8775 - val_loss: 156.5180 - val_RMSE: 2.9125\n",
      "Epoch 285/600\n",
      "22/22 [==============================] - 11s 515ms/step - loss: 116.3462 - RMSE: 2.8775 - val_loss: 156.3262 - val_RMSE: 2.9124\n",
      "Epoch 286/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.3148 - RMSE: 2.8775 - val_loss: 156.3950 - val_RMSE: 2.9128\n",
      "Epoch 287/600\n",
      "22/22 [==============================] - 11s 513ms/step - loss: 116.3429 - RMSE: 2.8773 - val_loss: 156.4745 - val_RMSE: 2.9126\n",
      "Epoch 288/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.3390 - RMSE: 2.8776 - val_loss: 156.3737 - val_RMSE: 2.9146\n",
      "Epoch 289/600\n",
      "22/22 [==============================] - 11s 518ms/step - loss: 116.3410 - RMSE: 2.8774 - val_loss: 156.3640 - val_RMSE: 2.9126\n",
      "Epoch 290/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.3474 - RMSE: 2.8775 - val_loss: 156.4110 - val_RMSE: 2.9126\n",
      "Epoch 291/600\n",
      "22/22 [==============================] - 11s 511ms/step - loss: 116.3069 - RMSE: 2.8773 - val_loss: 156.2400 - val_RMSE: 2.9144\n",
      "Epoch 292/600\n",
      "22/22 [==============================] - 11s 512ms/step - loss: 116.3465 - RMSE: 2.8776 - val_loss: 156.3388 - val_RMSE: 2.9151\n",
      "Epoch 293/600\n",
      "22/22 [==============================] - 11s 515ms/step - loss: 116.3264 - RMSE: 2.8774 - val_loss: 156.5779 - val_RMSE: 2.9114\n",
      "Epoch 294/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.3310 - RMSE: 2.8775 - val_loss: 156.5309 - val_RMSE: 2.9103\n",
      "Epoch 295/600\n",
      "22/22 [==============================] - 11s 513ms/step - loss: 116.3134 - RMSE: 2.8776 - val_loss: 156.7774 - val_RMSE: 2.9086\n",
      "Epoch 296/600\n",
      "22/22 [==============================] - 11s 512ms/step - loss: 116.3435 - RMSE: 2.8773 - val_loss: 156.4637 - val_RMSE: 2.9113\n",
      "Epoch 297/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.3176 - RMSE: 2.8774 - val_loss: 156.2908 - val_RMSE: 2.9130\n",
      "Epoch 298/600\n",
      "22/22 [==============================] - 11s 512ms/step - loss: 116.3387 - RMSE: 2.8776 - val_loss: 156.5078 - val_RMSE: 2.9093\n",
      "Epoch 299/600\n",
      "22/22 [==============================] - 11s 513ms/step - loss: 116.3270 - RMSE: 2.8775 - val_loss: 156.6793 - val_RMSE: 2.9095\n",
      "Epoch 300/600\n",
      "22/22 [==============================] - 11s 513ms/step - loss: 116.3175 - RMSE: 2.8773 - val_loss: 156.3636 - val_RMSE: 2.9121\n",
      "Epoch 301/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.3165 - RMSE: 2.8774 - val_loss: 156.1841 - val_RMSE: 2.9130\n",
      "Epoch 302/600\n",
      "22/22 [==============================] - 11s 515ms/step - loss: 116.3573 - RMSE: 2.8775 - val_loss: 156.5357 - val_RMSE: 2.9094\n",
      "Epoch 303/600\n",
      "22/22 [==============================] - 11s 515ms/step - loss: 116.3084 - RMSE: 2.8774 - val_loss: 156.6369 - val_RMSE: 2.9082\n",
      "Epoch 304/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.2955 - RMSE: 2.8773 - val_loss: 156.4487 - val_RMSE: 2.9108\n",
      "Epoch 305/600\n",
      "22/22 [==============================] - 11s 522ms/step - loss: 116.3016 - RMSE: 2.8775 - val_loss: 156.3845 - val_RMSE: 2.9102\n",
      "Epoch 306/600\n",
      "22/22 [==============================] - 12s 523ms/step - loss: 116.3348 - RMSE: 2.8773 - val_loss: 156.2243 - val_RMSE: 2.9116\n",
      "Epoch 307/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.2942 - RMSE: 2.8775 - val_loss: 157.0835 - val_RMSE: 2.9054\n",
      "Epoch 308/600\n",
      "22/22 [==============================] - 11s 515ms/step - loss: 116.3304 - RMSE: 2.8773 - val_loss: 156.4110 - val_RMSE: 2.9102\n",
      "Epoch 309/600\n",
      "22/22 [==============================] - 11s 512ms/step - loss: 116.2950 - RMSE: 2.8775 - val_loss: 156.6089 - val_RMSE: 2.9088\n",
      "Epoch 310/600\n",
      "22/22 [==============================] - 11s 515ms/step - loss: 116.2393 - RMSE: 2.8772 - val_loss: 156.3509 - val_RMSE: 2.9105\n",
      "Epoch 311/600\n",
      "22/22 [==============================] - 11s 512ms/step - loss: 116.3063 - RMSE: 2.8776 - val_loss: 156.7645 - val_RMSE: 2.9079\n",
      "Epoch 312/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.3260 - RMSE: 2.8773 - val_loss: 156.3244 - val_RMSE: 2.9095\n",
      "Epoch 313/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.3307 - RMSE: 2.8774 - val_loss: 156.7437 - val_RMSE: 2.9067\n",
      "Epoch 314/600\n",
      "22/22 [==============================] - 11s 517ms/step - loss: 116.3630 - RMSE: 2.8773 - val_loss: 156.2149 - val_RMSE: 2.9111\n",
      "Epoch 315/600\n",
      "22/22 [==============================] - 11s 515ms/step - loss: 116.2892 - RMSE: 2.8775 - val_loss: 156.3375 - val_RMSE: 2.9108\n",
      "Epoch 316/600\n",
      "22/22 [==============================] - 11s 512ms/step - loss: 116.2863 - RMSE: 2.8774 - val_loss: 156.5756 - val_RMSE: 2.9067\n",
      "Epoch 317/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.3298 - RMSE: 2.8774 - val_loss: 156.3155 - val_RMSE: 2.9108\n",
      "Epoch 318/600\n",
      "22/22 [==============================] - 11s 513ms/step - loss: 116.2805 - RMSE: 2.8774 - val_loss: 156.5438 - val_RMSE: 2.9083\n",
      "Epoch 319/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.2851 - RMSE: 2.8775 - val_loss: 156.4613 - val_RMSE: 2.9089\n",
      "Epoch 320/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.2766 - RMSE: 2.8773 - val_loss: 156.3377 - val_RMSE: 2.9091\n",
      "Epoch 321/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.3025 - RMSE: 2.8775 - val_loss: 156.4393 - val_RMSE: 2.9084\n",
      "Epoch 322/600\n",
      "22/22 [==============================] - 11s 513ms/step - loss: 116.2744 - RMSE: 2.8773 - val_loss: 156.5936 - val_RMSE: 2.9074\n",
      "Epoch 323/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.3371 - RMSE: 2.8775 - val_loss: 156.7673 - val_RMSE: 2.9054\n",
      "Epoch 324/600\n",
      "22/22 [==============================] - 11s 511ms/step - loss: 116.3021 - RMSE: 2.8773 - val_loss: 156.4523 - val_RMSE: 2.9086\n",
      "Epoch 325/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.3110 - RMSE: 2.8774 - val_loss: 156.6164 - val_RMSE: 2.9081\n",
      "Epoch 326/600\n",
      "22/22 [==============================] - 11s 512ms/step - loss: 116.3103 - RMSE: 2.8773 - val_loss: 156.2348 - val_RMSE: 2.9092\n",
      "Epoch 327/600\n",
      "22/22 [==============================] - 11s 515ms/step - loss: 116.3045 - RMSE: 2.8775 - val_loss: 155.9862 - val_RMSE: 2.9125\n",
      "Epoch 328/600\n",
      "22/22 [==============================] - 11s 512ms/step - loss: 116.2738 - RMSE: 2.8772 - val_loss: 156.2235 - val_RMSE: 2.9102\n",
      "Epoch 329/600\n",
      "22/22 [==============================] - 11s 513ms/step - loss: 116.3260 - RMSE: 2.8776 - val_loss: 156.3421 - val_RMSE: 2.9095\n",
      "Epoch 330/600\n",
      "22/22 [==============================] - 11s 513ms/step - loss: 116.3143 - RMSE: 2.8772 - val_loss: 156.4221 - val_RMSE: 2.9088\n",
      "Epoch 331/600\n",
      "22/22 [==============================] - 11s 516ms/step - loss: 116.3303 - RMSE: 2.8776 - val_loss: 156.3537 - val_RMSE: 2.9081\n",
      "Epoch 332/600\n",
      "22/22 [==============================] - 11s 517ms/step - loss: 116.3286 - RMSE: 2.8772 - val_loss: 156.1247 - val_RMSE: 2.9111\n",
      "Epoch 333/600\n",
      "22/22 [==============================] - 11s 513ms/step - loss: 116.3199 - RMSE: 2.8776 - val_loss: 156.8001 - val_RMSE: 2.9050\n",
      "Epoch 334/600\n",
      "22/22 [==============================] - 11s 513ms/step - loss: 116.3502 - RMSE: 2.8773 - val_loss: 156.4871 - val_RMSE: 2.9070\n",
      "Epoch 335/600\n",
      "22/22 [==============================] - 11s 512ms/step - loss: 116.3127 - RMSE: 2.8774 - val_loss: 156.2794 - val_RMSE: 2.9077\n",
      "Epoch 336/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.3310 - RMSE: 2.8773 - val_loss: 156.2895 - val_RMSE: 2.9087\n",
      "Epoch 337/600\n",
      "22/22 [==============================] - 11s 513ms/step - loss: 116.3247 - RMSE: 2.8774 - val_loss: 156.5455 - val_RMSE: 2.9060\n",
      "Epoch 338/600\n",
      "22/22 [==============================] - 11s 512ms/step - loss: 116.3183 - RMSE: 2.8774 - val_loss: 156.2881 - val_RMSE: 2.9095\n",
      "Epoch 339/600\n",
      "22/22 [==============================] - 11s 513ms/step - loss: 116.3598 - RMSE: 2.8774 - val_loss: 156.4313 - val_RMSE: 2.9077\n",
      "Epoch 340/600\n",
      "22/22 [==============================] - 11s 518ms/step - loss: 116.3003 - RMSE: 2.8774 - val_loss: 155.8635 - val_RMSE: 2.9134\n",
      "Epoch 341/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.2871 - RMSE: 2.8775 - val_loss: 156.0322 - val_RMSE: 2.9084\n",
      "Epoch 342/600\n",
      "22/22 [==============================] - 11s 518ms/step - loss: 116.2824 - RMSE: 2.8772 - val_loss: 156.2406 - val_RMSE: 2.9078\n",
      "Epoch 343/600\n",
      "22/22 [==============================] - 11s 515ms/step - loss: 116.2839 - RMSE: 2.8775 - val_loss: 156.4679 - val_RMSE: 2.9070\n",
      "Epoch 344/600\n",
      "22/22 [==============================] - 11s 515ms/step - loss: 116.2530 - RMSE: 2.8774 - val_loss: 156.4576 - val_RMSE: 2.9052\n",
      "Epoch 345/600\n",
      "22/22 [==============================] - 11s 517ms/step - loss: 116.3127 - RMSE: 2.8775 - val_loss: 156.3896 - val_RMSE: 2.9063\n",
      "Epoch 346/600\n",
      "22/22 [==============================] - 11s 516ms/step - loss: 116.3189 - RMSE: 2.8773 - val_loss: 156.1196 - val_RMSE: 2.9091\n",
      "Epoch 347/600\n",
      "22/22 [==============================] - 11s 517ms/step - loss: 116.2886 - RMSE: 2.8773 - val_loss: 155.9786 - val_RMSE: 2.9115\n",
      "Epoch 348/600\n",
      "22/22 [==============================] - 12s 546ms/step - loss: 116.3268 - RMSE: 2.8774 - val_loss: 156.4790 - val_RMSE: 2.9060\n",
      "Epoch 349/600\n",
      "22/22 [==============================] - 12s 555ms/step - loss: 116.3181 - RMSE: 2.8775 - val_loss: 156.4027 - val_RMSE: 2.9057\n",
      "Epoch 350/600\n",
      "22/22 [==============================] - 13s 576ms/step - loss: 116.3206 - RMSE: 2.8773 - val_loss: 155.8967 - val_RMSE: 2.9102\n",
      "Epoch 351/600\n",
      "22/22 [==============================] - 13s 595ms/step - loss: 116.3045 - RMSE: 2.8776 - val_loss: 156.6100 - val_RMSE: 2.9030\n",
      "Epoch 352/600\n",
      "22/22 [==============================] - 12s 558ms/step - loss: 116.3201 - RMSE: 2.8773 - val_loss: 156.1345 - val_RMSE: 2.9081\n",
      "Epoch 353/600\n",
      "22/22 [==============================] - 12s 561ms/step - loss: 116.3264 - RMSE: 2.8774 - val_loss: 155.9852 - val_RMSE: 2.9098\n",
      "Epoch 354/600\n",
      "22/22 [==============================] - 12s 526ms/step - loss: 116.2893 - RMSE: 2.8774 - val_loss: 156.1566 - val_RMSE: 2.9077\n",
      "Epoch 355/600\n",
      "22/22 [==============================] - 11s 512ms/step - loss: 116.3002 - RMSE: 2.8774 - val_loss: 156.0734 - val_RMSE: 2.9083\n",
      "Epoch 356/600\n",
      "22/22 [==============================] - 11s 512ms/step - loss: 116.2631 - RMSE: 2.8772 - val_loss: 155.9587 - val_RMSE: 2.9094\n",
      "Epoch 357/600\n",
      "22/22 [==============================] - 11s 512ms/step - loss: 116.2832 - RMSE: 2.8776 - val_loss: 156.2890 - val_RMSE: 2.9066\n",
      "Epoch 358/600\n",
      "22/22 [==============================] - 11s 512ms/step - loss: 116.3092 - RMSE: 2.8773 - val_loss: 156.1564 - val_RMSE: 2.9075\n",
      "Epoch 359/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.3390 - RMSE: 2.8774 - val_loss: 156.3745 - val_RMSE: 2.9045\n",
      "Epoch 360/600\n",
      "22/22 [==============================] - 11s 510ms/step - loss: 116.2802 - RMSE: 2.8773 - val_loss: 156.2328 - val_RMSE: 2.9066\n",
      "Epoch 361/600\n",
      "22/22 [==============================] - 12s 534ms/step - loss: 116.2967 - RMSE: 2.8774 - val_loss: 156.2605 - val_RMSE: 2.9066\n",
      "Epoch 362/600\n",
      "22/22 [==============================] - 12s 538ms/step - loss: 116.2882 - RMSE: 2.8773 - val_loss: 156.1176 - val_RMSE: 2.9073\n",
      "Epoch 363/600\n",
      "22/22 [==============================] - 12s 548ms/step - loss: 116.3203 - RMSE: 2.8775 - val_loss: 156.0339 - val_RMSE: 2.9072\n",
      "Epoch 364/600\n",
      "22/22 [==============================] - 11s 516ms/step - loss: 116.2977 - RMSE: 2.8772 - val_loss: 156.2064 - val_RMSE: 2.9058\n",
      "Epoch 365/600\n",
      "22/22 [==============================] - 12s 542ms/step - loss: 116.2684 - RMSE: 2.8774 - val_loss: 156.1446 - val_RMSE: 2.9072\n",
      "Epoch 366/600\n",
      "22/22 [==============================] - 12s 553ms/step - loss: 116.2609 - RMSE: 2.8773 - val_loss: 156.1590 - val_RMSE: 2.9058\n",
      "Epoch 367/600\n",
      "22/22 [==============================] - 12s 537ms/step - loss: 116.2742 - RMSE: 2.8776 - val_loss: 156.5492 - val_RMSE: 2.9040\n",
      "Epoch 368/600\n",
      "22/22 [==============================] - 12s 539ms/step - loss: 116.2820 - RMSE: 2.8772 - val_loss: 156.4969 - val_RMSE: 2.9035\n",
      "Epoch 369/600\n",
      "22/22 [==============================] - 12s 543ms/step - loss: 116.3027 - RMSE: 2.8774 - val_loss: 156.0554 - val_RMSE: 2.9078\n",
      "Epoch 370/600\n",
      "22/22 [==============================] - 12s 531ms/step - loss: 116.2548 - RMSE: 2.8772 - val_loss: 156.0925 - val_RMSE: 2.9065\n",
      "Epoch 371/600\n",
      "22/22 [==============================] - 13s 572ms/step - loss: 116.3186 - RMSE: 2.8775 - val_loss: 156.1952 - val_RMSE: 2.9050\n",
      "Epoch 372/600\n",
      "22/22 [==============================] - 12s 550ms/step - loss: 116.2817 - RMSE: 2.8773 - val_loss: 156.2546 - val_RMSE: 2.9055\n",
      "Epoch 373/600\n",
      "22/22 [==============================] - 13s 571ms/step - loss: 116.3277 - RMSE: 2.8773 - val_loss: 156.2721 - val_RMSE: 2.9053\n",
      "Epoch 374/600\n",
      "22/22 [==============================] - 12s 551ms/step - loss: 116.2834 - RMSE: 2.8773 - val_loss: 156.2230 - val_RMSE: 2.9058\n",
      "Epoch 375/600\n",
      "22/22 [==============================] - 14s 633ms/step - loss: 116.3184 - RMSE: 2.8776 - val_loss: 156.2097 - val_RMSE: 2.9044\n",
      "Epoch 376/600\n",
      "22/22 [==============================] - 12s 551ms/step - loss: 116.3088 - RMSE: 2.8772 - val_loss: 156.0859 - val_RMSE: 2.9061\n",
      "Epoch 377/600\n",
      "22/22 [==============================] - 12s 541ms/step - loss: 116.3074 - RMSE: 2.8775 - val_loss: 156.3255 - val_RMSE: 2.9049\n",
      "Epoch 378/600\n",
      "22/22 [==============================] - 12s 539ms/step - loss: 116.2834 - RMSE: 2.8772 - val_loss: 155.8863 - val_RMSE: 2.9085\n",
      "Epoch 379/600\n",
      "22/22 [==============================] - 12s 531ms/step - loss: 116.3575 - RMSE: 2.8776 - val_loss: 156.5569 - val_RMSE: 2.9013\n",
      "Epoch 380/600\n",
      "22/22 [==============================] - 11s 518ms/step - loss: 116.2884 - RMSE: 2.8773 - val_loss: 155.8331 - val_RMSE: 2.9075\n",
      "Epoch 381/600\n",
      "22/22 [==============================] - 11s 521ms/step - loss: 116.3594 - RMSE: 2.8773 - val_loss: 156.4180 - val_RMSE: 2.9044\n",
      "Epoch 382/600\n",
      "22/22 [==============================] - 12s 534ms/step - loss: 116.3295 - RMSE: 2.8773 - val_loss: 155.9711 - val_RMSE: 2.9068\n",
      "Epoch 383/600\n",
      "22/22 [==============================] - 12s 545ms/step - loss: 116.3165 - RMSE: 2.8774 - val_loss: 155.6817 - val_RMSE: 2.9098\n",
      "Epoch 384/600\n",
      "22/22 [==============================] - 12s 533ms/step - loss: 116.3026 - RMSE: 2.8774 - val_loss: 156.2496 - val_RMSE: 2.9038\n",
      "Epoch 385/600\n",
      "22/22 [==============================] - 12s 547ms/step - loss: 116.2980 - RMSE: 2.8775 - val_loss: 156.6707 - val_RMSE: 2.9009\n",
      "Epoch 386/600\n",
      "22/22 [==============================] - 12s 524ms/step - loss: 116.3294 - RMSE: 2.8773 - val_loss: 156.0604 - val_RMSE: 2.9046\n",
      "Epoch 387/600\n",
      "22/22 [==============================] - 12s 552ms/step - loss: 116.3139 - RMSE: 2.8773 - val_loss: 156.0006 - val_RMSE: 2.9078\n",
      "Epoch 388/600\n",
      "22/22 [==============================] - 13s 576ms/step - loss: 116.3032 - RMSE: 2.8774 - val_loss: 156.2926 - val_RMSE: 2.9028\n",
      "Epoch 389/600\n",
      "22/22 [==============================] - 13s 579ms/step - loss: 116.3180 - RMSE: 2.8774 - val_loss: 156.0383 - val_RMSE: 2.9059\n",
      "Epoch 390/600\n",
      "22/22 [==============================] - 12s 561ms/step - loss: 116.3209 - RMSE: 2.8775 - val_loss: 155.8429 - val_RMSE: 2.9066\n",
      "Epoch 391/600\n",
      "22/22 [==============================] - 12s 526ms/step - loss: 116.2416 - RMSE: 2.8774 - val_loss: 155.9711 - val_RMSE: 2.9069\n",
      "Epoch 392/600\n",
      "22/22 [==============================] - 12s 524ms/step - loss: 116.3110 - RMSE: 2.8772 - val_loss: 156.0865 - val_RMSE: 2.9058\n",
      "Epoch 393/600\n",
      "22/22 [==============================] - 11s 520ms/step - loss: 116.2975 - RMSE: 2.8776 - val_loss: 156.2359 - val_RMSE: 2.9032\n",
      "Epoch 394/600\n",
      "22/22 [==============================] - 11s 519ms/step - loss: 116.2541 - RMSE: 2.8771 - val_loss: 155.8403 - val_RMSE: 2.9065\n",
      "Epoch 395/600\n",
      "22/22 [==============================] - 11s 518ms/step - loss: 116.3225 - RMSE: 2.8777 - val_loss: 156.3376 - val_RMSE: 2.9025\n",
      "Epoch 396/600\n",
      "22/22 [==============================] - 11s 520ms/step - loss: 116.2941 - RMSE: 2.8772 - val_loss: 156.0836 - val_RMSE: 2.9049\n",
      "Epoch 397/600\n",
      "22/22 [==============================] - 11s 518ms/step - loss: 116.2702 - RMSE: 2.8774 - val_loss: 156.2868 - val_RMSE: 2.9022\n",
      "Epoch 398/600\n",
      "22/22 [==============================] - 11s 518ms/step - loss: 116.2743 - RMSE: 2.8773 - val_loss: 155.9817 - val_RMSE: 2.9054\n",
      "Epoch 399/600\n",
      "22/22 [==============================] - 11s 518ms/step - loss: 116.2881 - RMSE: 2.8774 - val_loss: 155.7656 - val_RMSE: 2.9071\n",
      "Epoch 400/600\n",
      "22/22 [==============================] - 11s 518ms/step - loss: 116.2760 - RMSE: 2.8773 - val_loss: 156.0471 - val_RMSE: 2.9056\n",
      "Epoch 401/600\n",
      "22/22 [==============================] - 11s 519ms/step - loss: 116.3173 - RMSE: 2.8773 - val_loss: 155.9906 - val_RMSE: 2.9050\n",
      "Epoch 402/600\n",
      "22/22 [==============================] - 11s 521ms/step - loss: 116.2687 - RMSE: 2.8774 - val_loss: 156.0841 - val_RMSE: 2.9032\n",
      "Epoch 403/600\n",
      "22/22 [==============================] - 11s 519ms/step - loss: 116.3000 - RMSE: 2.8774 - val_loss: 156.1063 - val_RMSE: 2.9045\n",
      "Epoch 404/600\n",
      "22/22 [==============================] - 11s 518ms/step - loss: 116.3205 - RMSE: 2.8773 - val_loss: 155.8923 - val_RMSE: 2.9046\n",
      "Epoch 405/600\n",
      "22/22 [==============================] - 11s 518ms/step - loss: 116.2892 - RMSE: 2.8774 - val_loss: 156.1560 - val_RMSE: 2.9034\n",
      "Epoch 406/600\n",
      "22/22 [==============================] - 11s 519ms/step - loss: 116.2771 - RMSE: 2.8774 - val_loss: 156.8174 - val_RMSE: 2.8980\n",
      "Epoch 407/600\n",
      "22/22 [==============================] - 11s 518ms/step - loss: 116.2758 - RMSE: 2.8774 - val_loss: 156.2249 - val_RMSE: 2.9024\n",
      "Epoch 408/600\n",
      "22/22 [==============================] - 12s 523ms/step - loss: 116.2296 - RMSE: 2.8773 - val_loss: 155.4484 - val_RMSE: 2.9111\n",
      "Epoch 409/600\n",
      "22/22 [==============================] - 11s 520ms/step - loss: 116.3070 - RMSE: 2.8773 - val_loss: 156.0208 - val_RMSE: 2.9051\n",
      "Epoch 410/600\n",
      "22/22 [==============================] - 11s 518ms/step - loss: 116.3262 - RMSE: 2.8775 - val_loss: 155.9361 - val_RMSE: 2.9047\n",
      "Epoch 411/600\n",
      "22/22 [==============================] - 11s 520ms/step - loss: 116.3360 - RMSE: 2.8773 - val_loss: 156.2206 - val_RMSE: 2.9033\n",
      "Epoch 412/600\n",
      "22/22 [==============================] - 11s 518ms/step - loss: 116.3057 - RMSE: 2.8773 - val_loss: 155.8190 - val_RMSE: 2.9058\n",
      "Epoch 413/600\n",
      "22/22 [==============================] - 11s 519ms/step - loss: 116.2765 - RMSE: 2.8775 - val_loss: 156.5513 - val_RMSE: 2.9002\n",
      "Epoch 414/600\n",
      "22/22 [==============================] - 11s 522ms/step - loss: 116.2634 - RMSE: 2.8772 - val_loss: 155.7647 - val_RMSE: 2.9059\n",
      "Epoch 415/600\n",
      "22/22 [==============================] - 11s 517ms/step - loss: 116.2879 - RMSE: 2.8774 - val_loss: 156.1309 - val_RMSE: 2.9038\n",
      "Epoch 416/600\n",
      "22/22 [==============================] - 12s 541ms/step - loss: 116.2792 - RMSE: 2.8775 - val_loss: 156.0658 - val_RMSE: 2.9040\n",
      "Epoch 417/600\n",
      "22/22 [==============================] - 12s 526ms/step - loss: 116.2865 - RMSE: 2.8772 - val_loss: 155.8777 - val_RMSE: 2.9065\n",
      "Epoch 418/600\n",
      "22/22 [==============================] - 11s 521ms/step - loss: 116.3035 - RMSE: 2.8775 - val_loss: 156.3770 - val_RMSE: 2.9009\n",
      "Epoch 419/600\n",
      "22/22 [==============================] - 11s 521ms/step - loss: 116.2886 - RMSE: 2.8774 - val_loss: 155.7824 - val_RMSE: 2.9054\n",
      "Epoch 420/600\n",
      "22/22 [==============================] - 11s 519ms/step - loss: 116.2710 - RMSE: 2.8773 - val_loss: 156.0933 - val_RMSE: 2.9026\n",
      "Epoch 421/600\n",
      "22/22 [==============================] - 11s 519ms/step - loss: 116.2934 - RMSE: 2.8775 - val_loss: 156.1897 - val_RMSE: 2.9037\n",
      "Epoch 422/600\n",
      "22/22 [==============================] - 11s 519ms/step - loss: 116.2738 - RMSE: 2.8773 - val_loss: 155.7247 - val_RMSE: 2.9051\n",
      "Epoch 423/600\n",
      "22/22 [==============================] - 11s 518ms/step - loss: 116.2715 - RMSE: 2.8774 - val_loss: 155.8986 - val_RMSE: 2.9047\n",
      "Epoch 424/600\n",
      "22/22 [==============================] - 11s 520ms/step - loss: 116.3042 - RMSE: 2.8773 - val_loss: 155.6977 - val_RMSE: 2.9060\n",
      "Epoch 425/600\n",
      "22/22 [==============================] - 11s 520ms/step - loss: 116.2751 - RMSE: 2.8774 - val_loss: 156.1174 - val_RMSE: 2.9031\n",
      "Epoch 426/600\n",
      "22/22 [==============================] - 11s 517ms/step - loss: 116.3265 - RMSE: 2.8774 - val_loss: 156.0526 - val_RMSE: 2.9028\n",
      "Epoch 427/600\n",
      "22/22 [==============================] - 11s 521ms/step - loss: 116.2870 - RMSE: 2.8773 - val_loss: 156.1756 - val_RMSE: 2.9028\n",
      "Epoch 428/600\n",
      "22/22 [==============================] - 11s 520ms/step - loss: 116.2977 - RMSE: 2.8773 - val_loss: 155.8166 - val_RMSE: 2.9047\n",
      "Epoch 429/600\n",
      "22/22 [==============================] - 11s 517ms/step - loss: 116.2979 - RMSE: 2.8774 - val_loss: 156.0362 - val_RMSE: 2.9021\n",
      "Epoch 430/600\n",
      "22/22 [==============================] - 11s 518ms/step - loss: 116.2556 - RMSE: 2.8772 - val_loss: 156.0616 - val_RMSE: 2.9024\n",
      "Epoch 431/600\n",
      "22/22 [==============================] - 11s 520ms/step - loss: 116.3026 - RMSE: 2.8775 - val_loss: 156.0309 - val_RMSE: 2.9029\n",
      "Epoch 432/600\n",
      "22/22 [==============================] - 11s 522ms/step - loss: 116.2806 - RMSE: 2.8774 - val_loss: 156.0983 - val_RMSE: 2.9019\n",
      "Epoch 433/600\n",
      "22/22 [==============================] - 11s 521ms/step - loss: 116.2577 - RMSE: 2.8773 - val_loss: 156.0004 - val_RMSE: 2.9043\n",
      "Epoch 434/600\n",
      "22/22 [==============================] - 11s 519ms/step - loss: 116.2325 - RMSE: 2.8772 - val_loss: 156.0282 - val_RMSE: 2.9017\n",
      "Epoch 435/600\n",
      "22/22 [==============================] - 11s 520ms/step - loss: 116.3126 - RMSE: 2.8776 - val_loss: 156.2487 - val_RMSE: 2.9004\n",
      "Epoch 436/600\n",
      "22/22 [==============================] - 11s 518ms/step - loss: 116.2955 - RMSE: 2.8771 - val_loss: 155.7873 - val_RMSE: 2.9037\n",
      "Epoch 437/600\n",
      "22/22 [==============================] - 11s 518ms/step - loss: 116.3046 - RMSE: 2.8775 - val_loss: 156.1531 - val_RMSE: 2.9018\n",
      "Epoch 438/600\n",
      "22/22 [==============================] - 12s 524ms/step - loss: 116.2858 - RMSE: 2.8772 - val_loss: 155.6327 - val_RMSE: 2.9055\n",
      "Epoch 439/600\n",
      "22/22 [==============================] - 12s 524ms/step - loss: 116.3133 - RMSE: 2.8774 - val_loss: 155.9641 - val_RMSE: 2.9016\n",
      "Epoch 440/600\n",
      "22/22 [==============================] - 11s 518ms/step - loss: 116.2870 - RMSE: 2.8772 - val_loss: 155.9179 - val_RMSE: 2.9028\n",
      "Epoch 441/600\n",
      "22/22 [==============================] - 11s 520ms/step - loss: 116.2886 - RMSE: 2.8776 - val_loss: 156.1482 - val_RMSE: 2.9008\n",
      "Epoch 442/600\n",
      "22/22 [==============================] - 11s 518ms/step - loss: 116.3013 - RMSE: 2.8772 - val_loss: 155.7475 - val_RMSE: 2.9039\n",
      "Epoch 443/600\n",
      "22/22 [==============================] - 11s 520ms/step - loss: 116.2711 - RMSE: 2.8774 - val_loss: 156.1341 - val_RMSE: 2.9014\n",
      "Epoch 444/600\n",
      "22/22 [==============================] - 11s 520ms/step - loss: 116.3020 - RMSE: 2.8773 - val_loss: 156.2889 - val_RMSE: 2.9002\n",
      "Epoch 445/600\n",
      "22/22 [==============================] - 11s 520ms/step - loss: 116.2754 - RMSE: 2.8774 - val_loss: 155.9411 - val_RMSE: 2.9024\n",
      "Epoch 446/600\n",
      "22/22 [==============================] - 11s 520ms/step - loss: 116.3043 - RMSE: 2.8773 - val_loss: 156.1606 - val_RMSE: 2.9003\n",
      "Epoch 447/600\n",
      "22/22 [==============================] - 11s 519ms/step - loss: 116.2624 - RMSE: 2.8773 - val_loss: 155.8912 - val_RMSE: 2.9035\n",
      "Epoch 448/600\n",
      "22/22 [==============================] - 12s 527ms/step - loss: 116.2755 - RMSE: 2.8773 - val_loss: 155.6581 - val_RMSE: 2.9037\n",
      "Epoch 449/600\n",
      "22/22 [==============================] - 12s 549ms/step - loss: 116.2992 - RMSE: 2.8774 - val_loss: 156.2808 - val_RMSE: 2.8990\n",
      "Epoch 450/600\n",
      "22/22 [==============================] - 11s 517ms/step - loss: 116.2904 - RMSE: 2.8774 - val_loss: 156.0881 - val_RMSE: 2.9007\n",
      "Epoch 451/600\n",
      "22/22 [==============================] - 12s 537ms/step - loss: 116.2521 - RMSE: 2.8772 - val_loss: 155.7723 - val_RMSE: 2.9042\n",
      "Epoch 452/600\n",
      "22/22 [==============================] - 12s 531ms/step - loss: 116.2786 - RMSE: 2.8775 - val_loss: 156.1323 - val_RMSE: 2.9003\n",
      "Epoch 453/600\n",
      "22/22 [==============================] - 12s 524ms/step - loss: 116.3139 - RMSE: 2.8774 - val_loss: 156.2064 - val_RMSE: 2.9004\n",
      "Epoch 454/600\n",
      "22/22 [==============================] - 11s 519ms/step - loss: 116.3184 - RMSE: 2.8773 - val_loss: 156.1539 - val_RMSE: 2.9005\n",
      "Epoch 455/600\n",
      "22/22 [==============================] - 11s 515ms/step - loss: 116.2780 - RMSE: 2.8773 - val_loss: 155.9835 - val_RMSE: 2.9012\n",
      "Epoch 456/600\n",
      "22/22 [==============================] - 13s 589ms/step - loss: 116.2977 - RMSE: 2.8774 - val_loss: 155.9710 - val_RMSE: 2.9024\n",
      "Epoch 457/600\n",
      "22/22 [==============================] - 12s 550ms/step - loss: 116.2264 - RMSE: 2.8773 - val_loss: 155.7547 - val_RMSE: 2.9030\n",
      "Epoch 458/600\n",
      "22/22 [==============================] - 11s 517ms/step - loss: 116.3016 - RMSE: 2.8773 - val_loss: 155.4547 - val_RMSE: 2.9056\n",
      "Epoch 459/600\n",
      "22/22 [==============================] - 11s 516ms/step - loss: 116.2763 - RMSE: 2.8774 - val_loss: 155.9327 - val_RMSE: 2.9006\n",
      "Epoch 460/600\n",
      "22/22 [==============================] - 11s 516ms/step - loss: 116.2657 - RMSE: 2.8774 - val_loss: 155.9016 - val_RMSE: 2.9024\n",
      "Epoch 461/600\n",
      "22/22 [==============================] - 11s 516ms/step - loss: 116.2609 - RMSE: 2.8772 - val_loss: 155.6712 - val_RMSE: 2.9035\n",
      "Epoch 462/600\n",
      "22/22 [==============================] - 11s 515ms/step - loss: 116.2587 - RMSE: 2.8774 - val_loss: 155.9893 - val_RMSE: 2.9012\n",
      "Epoch 463/600\n",
      "22/22 [==============================] - 11s 518ms/step - loss: 116.2573 - RMSE: 2.8773 - val_loss: 156.0255 - val_RMSE: 2.9016\n",
      "Epoch 464/600\n",
      "22/22 [==============================] - 11s 522ms/step - loss: 116.2954 - RMSE: 2.8772 - val_loss: 155.7788 - val_RMSE: 2.9020\n",
      "Epoch 465/600\n",
      "22/22 [==============================] - 11s 515ms/step - loss: 116.2738 - RMSE: 2.8774 - val_loss: 156.0740 - val_RMSE: 2.9006\n",
      "Epoch 466/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.2718 - RMSE: 2.8773 - val_loss: 155.8336 - val_RMSE: 2.9022\n",
      "Epoch 467/600\n",
      "22/22 [==============================] - 11s 513ms/step - loss: 116.2950 - RMSE: 2.8774 - val_loss: 155.7946 - val_RMSE: 2.9025\n",
      "Epoch 468/600\n",
      "22/22 [==============================] - 11s 516ms/step - loss: 116.2729 - RMSE: 2.8772 - val_loss: 155.5826 - val_RMSE: 2.9042\n",
      "Epoch 469/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.2890 - RMSE: 2.8774 - val_loss: 156.1639 - val_RMSE: 2.8999\n",
      "Epoch 470/600\n",
      "22/22 [==============================] - 12s 540ms/step - loss: 116.2883 - RMSE: 2.8774 - val_loss: 156.3093 - val_RMSE: 2.8972\n",
      "Epoch 471/600\n",
      "22/22 [==============================] - 13s 586ms/step - loss: 116.2692 - RMSE: 2.8774 - val_loss: 156.0379 - val_RMSE: 2.9012\n",
      "Epoch 472/600\n",
      "22/22 [==============================] - 14s 641ms/step - loss: 116.2726 - RMSE: 2.8773 - val_loss: 155.9087 - val_RMSE: 2.9003\n",
      "Epoch 473/600\n",
      "22/22 [==============================] - 14s 655ms/step - loss: 116.2512 - RMSE: 2.8774 - val_loss: 155.8889 - val_RMSE: 2.9003\n",
      "Epoch 474/600\n",
      "22/22 [==============================] - 12s 561ms/step - loss: 116.2721 - RMSE: 2.8772 - val_loss: 155.6983 - val_RMSE: 2.9018\n",
      "Epoch 475/600\n",
      "22/22 [==============================] - 13s 573ms/step - loss: 116.3149 - RMSE: 2.8773 - val_loss: 156.3932 - val_RMSE: 2.8983\n",
      "Epoch 476/600\n",
      "22/22 [==============================] - 12s 564ms/step - loss: 116.2782 - RMSE: 2.8773 - val_loss: 155.5648 - val_RMSE: 2.9025\n",
      "Epoch 477/600\n",
      "22/22 [==============================] - 13s 577ms/step - loss: 116.2990 - RMSE: 2.8774 - val_loss: 155.9955 - val_RMSE: 2.8995\n",
      "Epoch 478/600\n",
      "22/22 [==============================] - 13s 594ms/step - loss: 116.2393 - RMSE: 2.8773 - val_loss: 155.6770 - val_RMSE: 2.9033\n",
      "Epoch 479/600\n",
      "22/22 [==============================] - 13s 584ms/step - loss: 116.2377 - RMSE: 2.8773 - val_loss: 155.9157 - val_RMSE: 2.9004\n",
      "Epoch 480/600\n",
      "22/22 [==============================] - 11s 519ms/step - loss: 116.3007 - RMSE: 2.8774 - val_loss: 156.1097 - val_RMSE: 2.8992\n",
      "Epoch 481/600\n",
      "22/22 [==============================] - 11s 516ms/step - loss: 116.2775 - RMSE: 2.8773 - val_loss: 155.6030 - val_RMSE: 2.9024\n",
      "Epoch 482/600\n",
      "22/22 [==============================] - 11s 515ms/step - loss: 116.2505 - RMSE: 2.8774 - val_loss: 155.8848 - val_RMSE: 2.8993\n",
      "Epoch 483/600\n",
      "22/22 [==============================] - 12s 556ms/step - loss: 116.2570 - RMSE: 2.8773 - val_loss: 155.7355 - val_RMSE: 2.9015\n",
      "Epoch 484/600\n",
      "22/22 [==============================] - 11s 519ms/step - loss: 116.2434 - RMSE: 2.8773 - val_loss: 155.9778 - val_RMSE: 2.9006\n",
      "Epoch 485/600\n",
      "22/22 [==============================] - 11s 515ms/step - loss: 116.2795 - RMSE: 2.8773 - val_loss: 155.9601 - val_RMSE: 2.9001\n",
      "Epoch 486/600\n",
      "22/22 [==============================] - 11s 518ms/step - loss: 116.3094 - RMSE: 2.8774 - val_loss: 155.7967 - val_RMSE: 2.9007\n",
      "Epoch 487/600\n",
      "22/22 [==============================] - 11s 518ms/step - loss: 116.2713 - RMSE: 2.8772 - val_loss: 155.6685 - val_RMSE: 2.9027\n",
      "Epoch 488/600\n",
      "22/22 [==============================] - 11s 521ms/step - loss: 116.2958 - RMSE: 2.8772 - val_loss: 155.5790 - val_RMSE: 2.9014\n",
      "Epoch 489/600\n",
      "22/22 [==============================] - 11s 515ms/step - loss: 116.2637 - RMSE: 2.8774 - val_loss: 155.8418 - val_RMSE: 2.8995\n",
      "Epoch 490/600\n",
      "22/22 [==============================] - 11s 516ms/step - loss: 116.2635 - RMSE: 2.8774 - val_loss: 155.7527 - val_RMSE: 2.9003\n",
      "Epoch 491/600\n",
      "22/22 [==============================] - 11s 520ms/step - loss: 116.2289 - RMSE: 2.8773 - val_loss: 156.0919 - val_RMSE: 2.8981\n",
      "Epoch 492/600\n",
      "22/22 [==============================] - 11s 515ms/step - loss: 116.2790 - RMSE: 2.8773 - val_loss: 156.1156 - val_RMSE: 2.8983\n",
      "Epoch 493/600\n",
      "22/22 [==============================] - 11s 517ms/step - loss: 116.2861 - RMSE: 2.8774 - val_loss: 155.8238 - val_RMSE: 2.8999\n",
      "Epoch 494/600\n",
      "22/22 [==============================] - 11s 517ms/step - loss: 116.2946 - RMSE: 2.8773 - val_loss: 156.1718 - val_RMSE: 2.8971\n",
      "Epoch 495/600\n",
      "22/22 [==============================] - 11s 518ms/step - loss: 116.3174 - RMSE: 2.8773 - val_loss: 155.9698 - val_RMSE: 2.8993\n",
      "Epoch 496/600\n",
      "22/22 [==============================] - 11s 516ms/step - loss: 116.3165 - RMSE: 2.8773 - val_loss: 155.7590 - val_RMSE: 2.9006\n",
      "Epoch 497/600\n",
      "22/22 [==============================] - 11s 519ms/step - loss: 116.2841 - RMSE: 2.8773 - val_loss: 155.7729 - val_RMSE: 2.8990\n",
      "Epoch 498/600\n",
      "22/22 [==============================] - 11s 515ms/step - loss: 116.2601 - RMSE: 2.8773 - val_loss: 155.8572 - val_RMSE: 2.8996\n",
      "Epoch 499/600\n",
      "22/22 [==============================] - 11s 515ms/step - loss: 116.2927 - RMSE: 2.8774 - val_loss: 155.9203 - val_RMSE: 2.8992\n",
      "Epoch 500/600\n",
      "22/22 [==============================] - 11s 518ms/step - loss: 116.2630 - RMSE: 2.8773 - val_loss: 155.7528 - val_RMSE: 2.9002\n",
      "Epoch 501/600\n",
      "22/22 [==============================] - 11s 515ms/step - loss: 116.2975 - RMSE: 2.8774 - val_loss: 156.0171 - val_RMSE: 2.8988\n",
      "Epoch 502/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.2906 - RMSE: 2.8772 - val_loss: 155.6896 - val_RMSE: 2.9008\n",
      "Epoch 503/600\n",
      "22/22 [==============================] - 11s 515ms/step - loss: 116.2592 - RMSE: 2.8775 - val_loss: 155.6694 - val_RMSE: 2.9010\n",
      "Epoch 504/600\n",
      "22/22 [==============================] - 11s 515ms/step - loss: 116.2624 - RMSE: 2.8772 - val_loss: 155.6331 - val_RMSE: 2.8999\n",
      "Epoch 505/600\n",
      "22/22 [==============================] - 11s 515ms/step - loss: 116.2839 - RMSE: 2.8773 - val_loss: 155.8624 - val_RMSE: 2.8993\n",
      "Epoch 506/600\n",
      "22/22 [==============================] - 11s 515ms/step - loss: 116.2752 - RMSE: 2.8773 - val_loss: 155.8964 - val_RMSE: 2.8994\n",
      "Epoch 507/600\n",
      "22/22 [==============================] - 11s 515ms/step - loss: 116.3339 - RMSE: 2.8773 - val_loss: 155.5968 - val_RMSE: 2.9015\n",
      "Epoch 508/600\n",
      "22/22 [==============================] - 11s 516ms/step - loss: 116.3150 - RMSE: 2.8773 - val_loss: 155.4284 - val_RMSE: 2.9017\n",
      "Epoch 509/600\n",
      "22/22 [==============================] - 11s 515ms/step - loss: 116.2491 - RMSE: 2.8773 - val_loss: 155.6205 - val_RMSE: 2.9009\n",
      "Epoch 510/600\n",
      "22/22 [==============================] - 11s 515ms/step - loss: 116.2802 - RMSE: 2.8774 - val_loss: 155.6731 - val_RMSE: 2.9000\n",
      "Epoch 511/600\n",
      "22/22 [==============================] - 11s 515ms/step - loss: 116.2582 - RMSE: 2.8773 - val_loss: 155.7673 - val_RMSE: 2.8990\n",
      "Epoch 512/600\n",
      "22/22 [==============================] - 11s 516ms/step - loss: 116.2324 - RMSE: 2.8773 - val_loss: 155.5719 - val_RMSE: 2.9008\n",
      "Epoch 513/600\n",
      "22/22 [==============================] - 11s 517ms/step - loss: 116.2637 - RMSE: 2.8774 - val_loss: 156.1864 - val_RMSE: 2.8960\n",
      "Epoch 514/600\n",
      "22/22 [==============================] - 11s 517ms/step - loss: 116.3033 - RMSE: 2.8772 - val_loss: 155.2115 - val_RMSE: 2.9035\n",
      "Epoch 515/600\n",
      "22/22 [==============================] - 11s 515ms/step - loss: 116.2964 - RMSE: 2.8774 - val_loss: 155.6518 - val_RMSE: 2.9001\n",
      "Epoch 516/600\n",
      "22/22 [==============================] - 11s 517ms/step - loss: 116.3311 - RMSE: 2.8773 - val_loss: 155.4952 - val_RMSE: 2.9012\n",
      "Epoch 517/600\n",
      "22/22 [==============================] - 11s 519ms/step - loss: 116.2818 - RMSE: 2.8772 - val_loss: 155.7398 - val_RMSE: 2.8994\n",
      "Epoch 518/600\n",
      "22/22 [==============================] - 11s 518ms/step - loss: 116.2462 - RMSE: 2.8774 - val_loss: 155.8652 - val_RMSE: 2.8977\n",
      "Epoch 519/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.2724 - RMSE: 2.8773 - val_loss: 155.9732 - val_RMSE: 2.8978\n",
      "Epoch 520/600\n",
      "22/22 [==============================] - 11s 519ms/step - loss: 116.2445 - RMSE: 2.8774 - val_loss: 156.1854 - val_RMSE: 2.8954\n",
      "Epoch 521/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.2785 - RMSE: 2.8773 - val_loss: 155.3540 - val_RMSE: 2.9018\n",
      "Epoch 522/600\n",
      "22/22 [==============================] - 11s 515ms/step - loss: 116.2367 - RMSE: 2.8772 - val_loss: 156.0292 - val_RMSE: 2.8975\n",
      "Epoch 523/600\n",
      "22/22 [==============================] - 11s 516ms/step - loss: 116.2568 - RMSE: 2.8775 - val_loss: 155.9508 - val_RMSE: 2.8970\n",
      "Epoch 524/600\n",
      "22/22 [==============================] - 11s 515ms/step - loss: 116.2572 - RMSE: 2.8772 - val_loss: 155.2290 - val_RMSE: 2.9029\n",
      "Epoch 525/600\n",
      "22/22 [==============================] - 11s 516ms/step - loss: 116.2818 - RMSE: 2.8774 - val_loss: 155.4399 - val_RMSE: 2.9009\n",
      "Epoch 526/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.2844 - RMSE: 2.8773 - val_loss: 155.8176 - val_RMSE: 2.8985\n",
      "Epoch 527/600\n",
      "22/22 [==============================] - 11s 516ms/step - loss: 116.2834 - RMSE: 2.8772 - val_loss: 155.8980 - val_RMSE: 2.8980\n",
      "Epoch 528/600\n",
      "22/22 [==============================] - 11s 520ms/step - loss: 116.2435 - RMSE: 2.8774 - val_loss: 155.6160 - val_RMSE: 2.9007\n",
      "Epoch 529/600\n",
      "22/22 [==============================] - 11s 516ms/step - loss: 116.2727 - RMSE: 2.8772 - val_loss: 155.4336 - val_RMSE: 2.9012\n",
      "Epoch 530/600\n",
      "22/22 [==============================] - 11s 519ms/step - loss: 116.2327 - RMSE: 2.8773 - val_loss: 155.5544 - val_RMSE: 2.8998\n",
      "Epoch 531/600\n",
      "22/22 [==============================] - 11s 522ms/step - loss: 116.2819 - RMSE: 2.8773 - val_loss: 155.6896 - val_RMSE: 2.8988\n",
      "Epoch 532/600\n",
      "22/22 [==============================] - 12s 534ms/step - loss: 116.2818 - RMSE: 2.8773 - val_loss: 155.7402 - val_RMSE: 2.8990\n",
      "Epoch 533/600\n",
      "22/22 [==============================] - 11s 516ms/step - loss: 116.2750 - RMSE: 2.8773 - val_loss: 155.7261 - val_RMSE: 2.8985\n",
      "Epoch 534/600\n",
      "22/22 [==============================] - 11s 515ms/step - loss: 116.2638 - RMSE: 2.8773 - val_loss: 155.5676 - val_RMSE: 2.9003\n",
      "Epoch 535/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.3089 - RMSE: 2.8773 - val_loss: 155.5246 - val_RMSE: 2.9009\n",
      "Epoch 536/600\n",
      "22/22 [==============================] - 11s 516ms/step - loss: 116.2674 - RMSE: 2.8773 - val_loss: 155.5673 - val_RMSE: 2.8997\n",
      "Epoch 537/600\n",
      "22/22 [==============================] - 11s 515ms/step - loss: 116.2550 - RMSE: 2.8774 - val_loss: 155.7389 - val_RMSE: 2.8987\n",
      "Epoch 538/600\n",
      "22/22 [==============================] - 11s 517ms/step - loss: 116.2779 - RMSE: 2.8772 - val_loss: 155.6343 - val_RMSE: 2.8995\n",
      "Epoch 539/600\n",
      "22/22 [==============================] - 11s 517ms/step - loss: 116.2492 - RMSE: 2.8774 - val_loss: 155.6136 - val_RMSE: 2.8998\n",
      "Epoch 540/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.2458 - RMSE: 2.8772 - val_loss: 155.8657 - val_RMSE: 2.8972\n",
      "Epoch 541/600\n",
      "22/22 [==============================] - 11s 515ms/step - loss: 116.2707 - RMSE: 2.8774 - val_loss: 155.7258 - val_RMSE: 2.8982\n",
      "Epoch 542/600\n",
      "22/22 [==============================] - 11s 516ms/step - loss: 116.2356 - RMSE: 2.8772 - val_loss: 155.5741 - val_RMSE: 2.8999\n",
      "Epoch 543/600\n",
      "22/22 [==============================] - 11s 515ms/step - loss: 116.3011 - RMSE: 2.8774 - val_loss: 155.6842 - val_RMSE: 2.8994\n",
      "Epoch 544/600\n",
      "22/22 [==============================] - 11s 515ms/step - loss: 116.2668 - RMSE: 2.8772 - val_loss: 155.5578 - val_RMSE: 2.8994\n",
      "Epoch 545/600\n",
      "22/22 [==============================] - 11s 515ms/step - loss: 116.2857 - RMSE: 2.8775 - val_loss: 155.7135 - val_RMSE: 2.8988\n",
      "Epoch 546/600\n",
      "22/22 [==============================] - 11s 518ms/step - loss: 116.2729 - RMSE: 2.8772 - val_loss: 155.6611 - val_RMSE: 2.8991\n",
      "Epoch 547/600\n",
      "22/22 [==============================] - 11s 516ms/step - loss: 116.2616 - RMSE: 2.8773 - val_loss: 155.5199 - val_RMSE: 2.9004\n",
      "Epoch 548/600\n",
      "22/22 [==============================] - 11s 521ms/step - loss: 116.2838 - RMSE: 2.8773 - val_loss: 155.7370 - val_RMSE: 2.8983\n",
      "Epoch 549/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.2993 - RMSE: 2.8774 - val_loss: 155.4881 - val_RMSE: 2.9003\n",
      "Epoch 550/600\n",
      "22/22 [==============================] - 11s 516ms/step - loss: 116.2759 - RMSE: 2.8773 - val_loss: 155.5377 - val_RMSE: 2.8997\n",
      "Epoch 551/600\n",
      "22/22 [==============================] - 11s 517ms/step - loss: 116.3039 - RMSE: 2.8774 - val_loss: 155.8294 - val_RMSE: 2.8962\n",
      "Epoch 552/600\n",
      "22/22 [==============================] - 11s 518ms/step - loss: 116.2906 - RMSE: 2.8772 - val_loss: 155.7732 - val_RMSE: 2.8977\n",
      "Epoch 553/600\n",
      "22/22 [==============================] - 11s 517ms/step - loss: 116.2757 - RMSE: 2.8774 - val_loss: 155.4403 - val_RMSE: 2.8997\n",
      "Epoch 554/600\n",
      "22/22 [==============================] - 11s 517ms/step - loss: 116.2854 - RMSE: 2.8773 - val_loss: 155.7335 - val_RMSE: 2.8975\n",
      "Epoch 555/600\n",
      "22/22 [==============================] - 11s 519ms/step - loss: 116.2554 - RMSE: 2.8773 - val_loss: 155.7377 - val_RMSE: 2.8983\n",
      "Epoch 556/600\n",
      "22/22 [==============================] - 11s 515ms/step - loss: 116.3236 - RMSE: 2.8773 - val_loss: 155.5507 - val_RMSE: 2.8993\n",
      "Epoch 557/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.3018 - RMSE: 2.8774 - val_loss: 155.6079 - val_RMSE: 2.8990\n",
      "Epoch 558/600\n",
      "22/22 [==============================] - 11s 516ms/step - loss: 116.2840 - RMSE: 2.8773 - val_loss: 155.2177 - val_RMSE: 2.9024\n",
      "Epoch 559/600\n",
      "22/22 [==============================] - 11s 516ms/step - loss: 116.2655 - RMSE: 2.8773 - val_loss: 155.6469 - val_RMSE: 2.8996\n",
      "Epoch 560/600\n",
      "22/22 [==============================] - 11s 515ms/step - loss: 116.2738 - RMSE: 2.8774 - val_loss: 155.9158 - val_RMSE: 2.8962\n",
      "Epoch 561/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.2602 - RMSE: 2.8773 - val_loss: 155.3885 - val_RMSE: 2.9004\n",
      "Epoch 562/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.2253 - RMSE: 2.8774 - val_loss: 155.7687 - val_RMSE: 2.8969\n",
      "Epoch 563/600\n",
      "22/22 [==============================] - 11s 515ms/step - loss: 116.2653 - RMSE: 2.8773 - val_loss: 155.3786 - val_RMSE: 2.9002\n",
      "Epoch 564/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.2550 - RMSE: 2.8774 - val_loss: 155.5401 - val_RMSE: 2.8995\n",
      "Epoch 565/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.2579 - RMSE: 2.8773 - val_loss: 155.7601 - val_RMSE: 2.8969\n",
      "Epoch 566/600\n",
      "22/22 [==============================] - 11s 516ms/step - loss: 116.2528 - RMSE: 2.8773 - val_loss: 155.6598 - val_RMSE: 2.8981\n",
      "Epoch 567/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.2418 - RMSE: 2.8773 - val_loss: 155.5798 - val_RMSE: 2.8978\n",
      "Epoch 568/600\n",
      "22/22 [==============================] - 11s 517ms/step - loss: 116.3262 - RMSE: 2.8773 - val_loss: 155.6365 - val_RMSE: 2.8981\n",
      "Epoch 569/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.2848 - RMSE: 2.8773 - val_loss: 155.5859 - val_RMSE: 2.8983\n",
      "Epoch 570/600\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 116.2650 - RMSE: 2.8773 - val_loss: 155.6076 - val_RMSE: 2.8983\n",
      "Epoch 571/600\n",
      "22/22 [==============================] - 15s 660ms/step - loss: 116.2492 - RMSE: 2.8773 - val_loss: 155.6055 - val_RMSE: 2.8979\n",
      "Epoch 572/600\n",
      "22/22 [==============================] - 14s 654ms/step - loss: 116.2637 - RMSE: 2.8774 - val_loss: 155.8094 - val_RMSE: 2.8967\n",
      "Epoch 573/600\n",
      "22/22 [==============================] - 14s 659ms/step - loss: 116.2966 - RMSE: 2.8772 - val_loss: 155.5519 - val_RMSE: 2.8982\n",
      "Epoch 574/600\n",
      "22/22 [==============================] - 14s 658ms/step - loss: 116.2801 - RMSE: 2.8774 - val_loss: 155.8622 - val_RMSE: 2.8961\n",
      "Epoch 575/600\n",
      "22/22 [==============================] - 15s 669ms/step - loss: 116.2579 - RMSE: 2.8771 - val_loss: 155.4223 - val_RMSE: 2.8992\n",
      "Epoch 576/600\n",
      "22/22 [==============================] - 15s 669ms/step - loss: 116.2337 - RMSE: 2.8774 - val_loss: 155.7823 - val_RMSE: 2.8965\n",
      "Epoch 577/600\n",
      "22/22 [==============================] - 14s 656ms/step - loss: 116.2752 - RMSE: 2.8773 - val_loss: 155.9004 - val_RMSE: 2.8957\n",
      "Epoch 578/600\n",
      "22/22 [==============================] - 14s 654ms/step - loss: 116.2653 - RMSE: 2.8773 - val_loss: 155.4268 - val_RMSE: 2.8979\n",
      "Epoch 579/600\n",
      "22/22 [==============================] - 14s 657ms/step - loss: 116.2844 - RMSE: 2.8772 - val_loss: 155.6814 - val_RMSE: 2.8971\n",
      "Epoch 580/600\n",
      "22/22 [==============================] - 14s 657ms/step - loss: 116.3027 - RMSE: 2.8774 - val_loss: 155.2616 - val_RMSE: 2.9004\n",
      "Epoch 581/600\n",
      "22/22 [==============================] - 14s 655ms/step - loss: 116.2471 - RMSE: 2.8773 - val_loss: 155.4973 - val_RMSE: 2.8983\n",
      "Epoch 582/600\n",
      "22/22 [==============================] - 14s 658ms/step - loss: 116.2704 - RMSE: 2.8773 - val_loss: 155.5430 - val_RMSE: 2.8971\n",
      "Epoch 583/600\n",
      "22/22 [==============================] - 14s 656ms/step - loss: 116.2893 - RMSE: 2.8773 - val_loss: 155.8773 - val_RMSE: 2.8953\n",
      "Epoch 584/600\n",
      "22/22 [==============================] - 14s 652ms/step - loss: 116.2710 - RMSE: 2.8773 - val_loss: 155.6731 - val_RMSE: 2.8977\n",
      "Epoch 585/600\n",
      "22/22 [==============================] - 15s 662ms/step - loss: 116.2454 - RMSE: 2.8773 - val_loss: 155.7455 - val_RMSE: 2.8965\n",
      "Epoch 586/600\n",
      "22/22 [==============================] - 14s 653ms/step - loss: 116.2615 - RMSE: 2.8772 - val_loss: 155.3198 - val_RMSE: 2.8995\n",
      "Epoch 587/600\n",
      "22/22 [==============================] - 14s 653ms/step - loss: 116.2444 - RMSE: 2.8774 - val_loss: 155.6734 - val_RMSE: 2.8965\n",
      "Epoch 588/600\n",
      "22/22 [==============================] - 15s 664ms/step - loss: 116.3107 - RMSE: 2.8772 - val_loss: 155.7106 - val_RMSE: 2.8971\n",
      "Epoch 589/600\n",
      "22/22 [==============================] - 14s 655ms/step - loss: 116.2416 - RMSE: 2.8773 - val_loss: 155.2870 - val_RMSE: 2.8992\n",
      "Epoch 590/600\n",
      "22/22 [==============================] - 14s 654ms/step - loss: 116.2728 - RMSE: 2.8773 - val_loss: 155.2837 - val_RMSE: 2.8997\n",
      "Epoch 591/600\n",
      "22/22 [==============================] - 14s 655ms/step - loss: 116.2325 - RMSE: 2.8773 - val_loss: 155.4011 - val_RMSE: 2.8977\n",
      "Epoch 592/600\n",
      "22/22 [==============================] - 15s 664ms/step - loss: 116.2318 - RMSE: 2.8773 - val_loss: 155.3749 - val_RMSE: 2.8985\n",
      "Epoch 593/600\n",
      "22/22 [==============================] - 14s 655ms/step - loss: 116.2458 - RMSE: 2.8772 - val_loss: 155.3019 - val_RMSE: 2.8993\n",
      "Epoch 594/600\n",
      "22/22 [==============================] - 14s 658ms/step - loss: 116.2668 - RMSE: 2.8773 - val_loss: 155.7634 - val_RMSE: 2.8956\n",
      "Epoch 595/600\n",
      "22/22 [==============================] - 14s 656ms/step - loss: 116.2748 - RMSE: 2.8774 - val_loss: 155.6510 - val_RMSE: 2.8971\n",
      "Epoch 596/600\n",
      "22/22 [==============================] - 14s 655ms/step - loss: 116.2645 - RMSE: 2.8773 - val_loss: 155.4972 - val_RMSE: 2.8974\n",
      "Epoch 597/600\n",
      "22/22 [==============================] - 14s 652ms/step - loss: 116.2384 - RMSE: 2.8772 - val_loss: 155.5600 - val_RMSE: 2.8967\n",
      "Epoch 598/600\n",
      "22/22 [==============================] - 14s 655ms/step - loss: 116.2577 - RMSE: 2.8773 - val_loss: 155.5882 - val_RMSE: 2.8967\n",
      "Epoch 599/600\n",
      "22/22 [==============================] - 14s 655ms/step - loss: 116.2888 - RMSE: 2.8773 - val_loss: 155.2116 - val_RMSE: 2.8988\n",
      "Epoch 600/600\n",
      "22/22 [==============================] - 14s 643ms/step - loss: 116.2473 - RMSE: 2.8773 - val_loss: 155.2551 - val_RMSE: 2.8997\n"
     ]
    }
   ],
   "source": [
    "history = dmf.model.fit(\n",
    "            {\"P_input\": X1_train, \"Q_input\": X2_train},\n",
    "            y = y_train,\n",
    "            batch_size=256,\n",
    "            validation_split=0.3,\n",
    "            epochs=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot  as plt\n",
    "plt.plot(history.history['loss'], label='training')\n",
    "plt.plot(history.history['val_loss'], label='validation')\n",
    "plt.title('Loss')\n",
    "plt.ylabel('loss value')\n",
    "plt.xlabel('No. epoch')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot  as plt\n",
    "plt.plot(history.history['RMSE'], label='training')\n",
    "plt.plot(history.history['val_RMSE'], label='validation')\n",
    "plt.title('RMSE')\n",
    "plt.ylabel('RMSE value')\n",
    "plt.xlabel('No. epoch')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSE on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = dmf.model.predict({\"P_input\": X1_test, \"Q_input\": X2_test})\n",
    "m = keras.metrics.RootMeanSquaredError()\n",
    "m.update_state(y_test, y_pred)\n",
    "print(f'RMSE = {m.result()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
